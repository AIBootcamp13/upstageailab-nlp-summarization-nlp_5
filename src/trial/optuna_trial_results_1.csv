trial_number,learning_rate,weight_decay,batch_size,num_train_epochs,warmup_steps,gradient_accumulation_steps,eval_rouge-l
0,2.9607793207038128e-05,0.07908444509572618,8,3,500,8,0.29873008165260473
1,3.877663332261394e-05,0.030876117442686635,32,20,0,2,0.3420422773738094
2,7.563476122688711e-05,0.09345838512646389,16,10,100,4,0.3447656738651891
3,0.00016398000992292927,0.07648971572158063,16,20,0,8,0.3356085280420355
4,1.4602931305693259e-06,0.030068983956038343,8,5,0,2,0.2805807090976539
5,1.706374386266006e-06,0.06911529668129522,16,3,500,1,0.23386467449614645
6,0.00023181430224719548,0.09680126965591018,8,20,500,4,0.33956981678329606
7,0.0001878255891394659,0.06990169656977595,16,20,500,8,0.33839357398565234
8,3.0486757386478227e-06,0.09506222815298779,64,20,10,8,0.17390022470431346
9,6.411254460093557e-05,0.002250068677315298,8,20,10,4,0.34130827209052905
10,9.846918468687899e-06,0.04864997503717095,64,10,100,4,0.24139226976694514
11,4.618186606142455e-05,0.030424395824404767,32,10,100,2,0.3425216873430965
12,9.840590489849004e-06,0.024389824706674598,32,10,100,2,0.3387822910915713
13,9.022955572882345e-05,0.04674002018935567,32,10,100,1,0.3440566928879425
14,9.9402756508081e-05,0.05258096492967547,16,10,100,1,0.33415674846454485
15,2.053482925576905e-05,0.05149996651973728,32,10,100,1,0.34469606888072923
16,1.487881935889045e-05,0.011345825788395589,16,5,100,4,0.342791999484691
17,0.0003616176214889618,0.05941569805511021,32,10,100,1,0.32788690897637596
18,4.320050930751517e-06,0.08697870614841799,64,10,100,1,0.3270809224970481
19,2.1125315703386168e-05,0.04096942722234521,32,10,10,4,0.3466012774065666
