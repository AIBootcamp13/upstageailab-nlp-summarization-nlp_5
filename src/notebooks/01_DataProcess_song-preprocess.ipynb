{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e563a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "project_dir = \"/data/ephemeral/home/nlp-5/song/\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\n",
    "    project_dir\n",
    ")\n",
    "from src.utils.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(project_dir, 'data','train.csv'))\n",
    "val_df = pd.read_csv(os.path.join(project_dir, 'data','dev.csv'))\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(project_dir, 'data','test.csv'))\n",
    "sub_df = pd.read_csv(os.path.join(project_dir, 'outputs', 'exp_aug_0730191312', 'submission_0730191312-0.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d93cd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /data/ephemeral/home/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') # nltk 내장 stopword 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4a42f",
   "metadata": {},
   "source": [
    "### 불용어 분석 \n",
    "- 토큰의 빈도를 분석하여 불용어 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffcb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")\n",
    "special_tokens = [\n",
    "    '#Person1#','#Person2#','#Person3#','#Person4#','#Person5#','#Person6#','#Person7#',\n",
    "    '#PhoneNumber#','#Address#','#DateOfBirth#','#PassportNumber#','#SSN#','#CardNumber#','#CarNumber#','#Email#'\n",
    "]\n",
    "special_tokens_dict={'additional_special_tokens':special_tokens}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985ce784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13455/13455 [00:02<00:00, 4759.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "all_dialogues = pd.concat([train_df['dialogue'], val_df['dialogue'], test_df['dialogue']])\n",
    "all_tokens = []\n",
    "\n",
    "for text in tqdm(all_dialogues):\n",
    "    # 토크나이저를 사용하여 텍스트를 토큰화합니다.\n",
    "    # .tokenize() 메서드는 문자열 토큰 리스트를 반환합니다.\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    all_tokens.extend(tokens)\n",
    "len_all_tokens = len(all_tokens)\n",
    "# 4. 토큰 빈도 계산\n",
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32991a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 빈도가 높은 상위 50개 토큰:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:</td>\n",
       "      <td>127675</td>\n",
       "      <td>6.239392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#</td>\n",
       "      <td>66318</td>\n",
       "      <td>3.240917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person2#</td>\n",
       "      <td>60997</td>\n",
       "      <td>2.980883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>39118</td>\n",
       "      <td>1.911671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>36281</td>\n",
       "      <td>1.773028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n</td>\n",
       "      <td>25071</td>\n",
       "      <td>1.225203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.\\n</td>\n",
       "      <td>19033</td>\n",
       "      <td>0.930130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>요.</td>\n",
       "      <td>17515</td>\n",
       "      <td>0.855946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?\\n</td>\n",
       "      <td>14325</td>\n",
       "      <td>0.700053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>?</td>\n",
       "      <td>12970</td>\n",
       "      <td>0.633835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>에</td>\n",
       "      <td>11830</td>\n",
       "      <td>0.578124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>수</td>\n",
       "      <td>10904</td>\n",
       "      <td>0.532871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>이</td>\n",
       "      <td>9417</td>\n",
       "      <td>0.460203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>해</td>\n",
       "      <td>9278</td>\n",
       "      <td>0.453410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>어.</td>\n",
       "      <td>8833</td>\n",
       "      <td>0.431663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>정말</td>\n",
       "      <td>8827</td>\n",
       "      <td>0.431370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>도</td>\n",
       "      <td>8357</td>\n",
       "      <td>0.408401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>네</td>\n",
       "      <td>8259</td>\n",
       "      <td>0.403612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>!</td>\n",
       "      <td>7727</td>\n",
       "      <td>0.377613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>요?\\n</td>\n",
       "      <td>7702</td>\n",
       "      <td>0.376392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>것</td>\n",
       "      <td>7311</td>\n",
       "      <td>0.357284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>있어</td>\n",
       "      <td>7267</td>\n",
       "      <td>0.355133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>게</td>\n",
       "      <td>6499</td>\n",
       "      <td>0.317602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>어</td>\n",
       "      <td>6428</td>\n",
       "      <td>0.314132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>좀</td>\n",
       "      <td>6355</td>\n",
       "      <td>0.310565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>안</td>\n",
       "      <td>6295</td>\n",
       "      <td>0.307632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>은</td>\n",
       "      <td>6273</td>\n",
       "      <td>0.306557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>가</td>\n",
       "      <td>6187</td>\n",
       "      <td>0.302355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>좋아</td>\n",
       "      <td>6163</td>\n",
       "      <td>0.301182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>아</td>\n",
       "      <td>6018</td>\n",
       "      <td>0.294096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>해</td>\n",
       "      <td>5705</td>\n",
       "      <td>0.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>잘</td>\n",
       "      <td>5398</td>\n",
       "      <td>0.263797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>요.\\n</td>\n",
       "      <td>5349</td>\n",
       "      <td>0.261402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>겠</td>\n",
       "      <td>5287</td>\n",
       "      <td>0.258372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>에서</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.251921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>할</td>\n",
       "      <td>5122</td>\n",
       "      <td>0.250309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>5116</td>\n",
       "      <td>0.250016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>그</td>\n",
       "      <td>5068</td>\n",
       "      <td>0.247670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>이</td>\n",
       "      <td>5019</td>\n",
       "      <td>0.245275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>더</td>\n",
       "      <td>5001</td>\n",
       "      <td>0.244396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>네</td>\n",
       "      <td>4995</td>\n",
       "      <td>0.244102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>야</td>\n",
       "      <td>4835</td>\n",
       "      <td>0.236283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>을</td>\n",
       "      <td>4808</td>\n",
       "      <td>0.234964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>같아</td>\n",
       "      <td>4784</td>\n",
       "      <td>0.233791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>요?</td>\n",
       "      <td>4778</td>\n",
       "      <td>0.233498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>어요.</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.229002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>는</td>\n",
       "      <td>4558</td>\n",
       "      <td>0.222746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>요,</td>\n",
       "      <td>4526</td>\n",
       "      <td>0.221183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>어.\\n</td>\n",
       "      <td>4514</td>\n",
       "      <td>0.220596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>주</td>\n",
       "      <td>4429</td>\n",
       "      <td>0.216442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token   count     ratio\n",
       "0           :  127675  6.239392\n",
       "1   #Person1#   66318  3.240917\n",
       "2   #Person2#   60997  2.980883\n",
       "3           .   39118  1.911671\n",
       "4           ,   36281  1.773028\n",
       "5          \\n   25071  1.225203\n",
       "6         .\\n   19033  0.930130\n",
       "7          요.   17515  0.855946\n",
       "8         ?\\n   14325  0.700053\n",
       "9           ?   12970  0.633835\n",
       "10          에   11830  0.578124\n",
       "11          수   10904  0.532871\n",
       "12          이    9417  0.460203\n",
       "13          해    9278  0.453410\n",
       "14         어.    8833  0.431663\n",
       "15         정말    8827  0.431370\n",
       "16          도    8357  0.408401\n",
       "17          네    8259  0.403612\n",
       "18          !    7727  0.377613\n",
       "19       요?\\n    7702  0.376392\n",
       "20          것    7311  0.357284\n",
       "21         있어    7267  0.355133\n",
       "22          게    6499  0.317602\n",
       "23          어    6428  0.314132\n",
       "24          좀    6355  0.310565\n",
       "25          안    6295  0.307632\n",
       "26          은    6273  0.306557\n",
       "27          가    6187  0.302355\n",
       "28         좋아    6163  0.301182\n",
       "29          아    6018  0.294096\n",
       "30          해    5705  0.278800\n",
       "31          잘    5398  0.263797\n",
       "32       요.\\n    5349  0.261402\n",
       "33          겠    5287  0.258372\n",
       "34         에서    5155  0.251921\n",
       "35          할    5122  0.250309\n",
       "36               5116  0.250016\n",
       "37          그    5068  0.247670\n",
       "38          이    5019  0.245275\n",
       "39          더    5001  0.244396\n",
       "40          네    4995  0.244102\n",
       "41          야    4835  0.236283\n",
       "42          을    4808  0.234964\n",
       "43         같아    4784  0.233791\n",
       "44         요?    4778  0.233498\n",
       "45        어요.    4686  0.229002\n",
       "46          는    4558  0.222746\n",
       "47         요,    4526  0.221183\n",
       "48       어.\\n    4514  0.220596\n",
       "49          주    4429  0.216442"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 가장 빈도가 높은 50개 토큰 출력\n",
    "print(\"가장 빈도가 높은 상위 50개 토큰:\")\n",
    "token_counts_df = []\n",
    "for token, count in token_counts.items():\n",
    "    token = tokenizer.convert_tokens_to_string([token])\n",
    "    # print(f\"토큰: '{token}', 빈도: {count}, 비율: {count/len_all_tokens*100:.3f}%\")\n",
    "    token_counts_df.append([token, count, count/len_all_tokens*100])\n",
    "token_counts_df = pd.DataFrame(\n",
    "    data=token_counts_df,\n",
    "    columns=['token', 'count', 'ratio']\n",
    ")\n",
    "token_counts_df = token_counts_df.sort_values('count', ascending=False)\n",
    "token_counts_df = token_counts_df.reset_index(drop=True)\n",
    "token_counts_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d75f06",
   "metadata": {},
   "source": [
    "- special token 추가\n",
    "    - `\\n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2707ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")\n",
    "special_tokens = [\n",
    "    '#Person1#','#Person2#','#Person3#','#Person4#','#Person5#','#Person6#','#Person7#',\n",
    "    '#PhoneNumber#','#Address#','#DateOfBirth#','#PassportNumber#','#SSN#','#CardNumber#','#CarNumber#','#Email#',\n",
    "    '\\n'\n",
    "]\n",
    "special_tokens_dict={'additional_special_tokens':special_tokens}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bd215c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13455/13455 [00:02<00:00, 4688.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "all_dialogues = pd.concat([train_df['dialogue'], val_df['dialogue'], test_df['dialogue']])\n",
    "all_tokens = []\n",
    "\n",
    "for text in tqdm(all_dialogues):\n",
    "    # 토크나이저를 사용하여 텍스트를 토큰화합니다.\n",
    "    # .tokenize() 메서드는 문자열 토큰 리스트를 반환합니다.\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    all_tokens.extend(tokens)\n",
    "# 4. 토큰 빈도 계산\n",
    "token_counts = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d42969fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 빈도가 높은 상위 50개 토큰:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:</td>\n",
       "      <td>127675</td>\n",
       "      <td>5.874355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n</td>\n",
       "      <td>114131</td>\n",
       "      <td>5.251193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#</td>\n",
       "      <td>66318</td>\n",
       "      <td>3.051306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person2#</td>\n",
       "      <td>60997</td>\n",
       "      <td>2.806486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>55155</td>\n",
       "      <td>2.537694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>36282</td>\n",
       "      <td>1.669343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?</td>\n",
       "      <td>30658</td>\n",
       "      <td>1.410581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>30176</td>\n",
       "      <td>1.388405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>요.</td>\n",
       "      <td>27788</td>\n",
       "      <td>1.278532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>요?</td>\n",
       "      <td>19908</td>\n",
       "      <td>0.915972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>어.</td>\n",
       "      <td>13340</td>\n",
       "      <td>0.613776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>에</td>\n",
       "      <td>12029</td>\n",
       "      <td>0.553457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>수</td>\n",
       "      <td>10904</td>\n",
       "      <td>0.501695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>해</td>\n",
       "      <td>10073</td>\n",
       "      <td>0.463461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>!</td>\n",
       "      <td>9975</td>\n",
       "      <td>0.458952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>이</td>\n",
       "      <td>9761</td>\n",
       "      <td>0.449106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>정말</td>\n",
       "      <td>8827</td>\n",
       "      <td>0.406132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>도</td>\n",
       "      <td>8357</td>\n",
       "      <td>0.384507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>어요.</td>\n",
       "      <td>8221</td>\n",
       "      <td>0.378250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>네</td>\n",
       "      <td>8153</td>\n",
       "      <td>0.375121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>어</td>\n",
       "      <td>7802</td>\n",
       "      <td>0.358972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>것</td>\n",
       "      <td>7311</td>\n",
       "      <td>0.336381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>있어</td>\n",
       "      <td>7267</td>\n",
       "      <td>0.334356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>게</td>\n",
       "      <td>6499</td>\n",
       "      <td>0.299020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>좀</td>\n",
       "      <td>6355</td>\n",
       "      <td>0.292395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>해</td>\n",
       "      <td>6333</td>\n",
       "      <td>0.291383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>안</td>\n",
       "      <td>6295</td>\n",
       "      <td>0.289634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>은</td>\n",
       "      <td>6290</td>\n",
       "      <td>0.289404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>가</td>\n",
       "      <td>6220</td>\n",
       "      <td>0.286184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>좋아</td>\n",
       "      <td>6163</td>\n",
       "      <td>0.283561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>아</td>\n",
       "      <td>6017</td>\n",
       "      <td>0.276844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>나</td>\n",
       "      <td>5640</td>\n",
       "      <td>0.259498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>야.</td>\n",
       "      <td>5636</td>\n",
       "      <td>0.259314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>같아</td>\n",
       "      <td>5525</td>\n",
       "      <td>0.254206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>세요.</td>\n",
       "      <td>5463</td>\n",
       "      <td>0.251354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>잘</td>\n",
       "      <td>5398</td>\n",
       "      <td>0.248363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>겠</td>\n",
       "      <td>5396</td>\n",
       "      <td>0.248271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>네</td>\n",
       "      <td>5177</td>\n",
       "      <td>0.238195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>에서</td>\n",
       "      <td>5155</td>\n",
       "      <td>0.237183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>할</td>\n",
       "      <td>5122</td>\n",
       "      <td>0.235664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>그</td>\n",
       "      <td>5067</td>\n",
       "      <td>0.233134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>이</td>\n",
       "      <td>5019</td>\n",
       "      <td>0.230925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>더</td>\n",
       "      <td>5001</td>\n",
       "      <td>0.230097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>을</td>\n",
       "      <td>4733</td>\n",
       "      <td>0.217766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>는</td>\n",
       "      <td>4559</td>\n",
       "      <td>0.209761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>요,</td>\n",
       "      <td>4526</td>\n",
       "      <td>0.208242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>주</td>\n",
       "      <td>4429</td>\n",
       "      <td>0.203779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>지</td>\n",
       "      <td>4339</td>\n",
       "      <td>0.199638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>알</td>\n",
       "      <td>4258</td>\n",
       "      <td>0.195912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>어떻게</td>\n",
       "      <td>4229</td>\n",
       "      <td>0.194577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token   count     ratio\n",
       "0           :  127675  5.874355\n",
       "1          \\n  114131  5.251193\n",
       "2   #Person1#   66318  3.051306\n",
       "3   #Person2#   60997  2.806486\n",
       "4           .   55155  2.537694\n",
       "5           ,   36282  1.669343\n",
       "6           ?   30658  1.410581\n",
       "7               30176  1.388405\n",
       "8          요.   27788  1.278532\n",
       "9          요?   19908  0.915972\n",
       "10         어.   13340  0.613776\n",
       "11          에   12029  0.553457\n",
       "12          수   10904  0.501695\n",
       "13          해   10073  0.463461\n",
       "14          !    9975  0.458952\n",
       "15          이    9761  0.449106\n",
       "16         정말    8827  0.406132\n",
       "17          도    8357  0.384507\n",
       "18        어요.    8221  0.378250\n",
       "19          네    8153  0.375121\n",
       "20          어    7802  0.358972\n",
       "21          것    7311  0.336381\n",
       "22         있어    7267  0.334356\n",
       "23          게    6499  0.299020\n",
       "24          좀    6355  0.292395\n",
       "25          해    6333  0.291383\n",
       "26          안    6295  0.289634\n",
       "27          은    6290  0.289404\n",
       "28          가    6220  0.286184\n",
       "29         좋아    6163  0.283561\n",
       "30          아    6017  0.276844\n",
       "31          나    5640  0.259498\n",
       "32         야.    5636  0.259314\n",
       "33         같아    5525  0.254206\n",
       "34        세요.    5463  0.251354\n",
       "35          잘    5398  0.248363\n",
       "36          겠    5396  0.248271\n",
       "37          네    5177  0.238195\n",
       "38         에서    5155  0.237183\n",
       "39          할    5122  0.235664\n",
       "40          그    5067  0.233134\n",
       "41          이    5019  0.230925\n",
       "42          더    5001  0.230097\n",
       "43          을    4733  0.217766\n",
       "44          는    4559  0.209761\n",
       "45         요,    4526  0.208242\n",
       "46          주    4429  0.203779\n",
       "47          지    4339  0.199638\n",
       "48          알    4258  0.195912\n",
       "49        어떻게    4229  0.194577"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 가장 빈도가 높은 50개 토큰 출력\n",
    "print(\"가장 빈도가 높은 상위 50개 토큰:\")\n",
    "token_counts_df = []\n",
    "len_token_counts = sum(token_counts.values())\n",
    "for token, count in token_counts.items():\n",
    "    token = tokenizer.convert_tokens_to_string([token])\n",
    "    # print(f\"토큰: '{token}', 빈도: {count}, 비율: {count/len_all_tokens*100:.3f}%\")\n",
    "    token_counts_df.append([token, count, count/len_token_counts*100])\n",
    "token_counts_df = pd.DataFrame(\n",
    "    data=token_counts_df,\n",
    "    columns=['token', 'count', 'ratio']\n",
    ")\n",
    "token_counts_df = token_counts_df.sort_values('count', ascending=False)\n",
    "token_counts_df = token_counts_df.reset_index(drop=True)\n",
    "token_counts_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c4604",
   "metadata": {},
   "source": [
    "### 영단어 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94e267",
   "metadata": {},
   "source": [
    "- 2개의 연속된 영단어 검출\n",
    "    - 영어 이름 검색 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70c44d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13455/13455 [00:00<00:00, 77399.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Smith</td>\n",
       "      <td>49</td>\n",
       "      <td>2.820956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr. Brown</td>\n",
       "      <td>43</td>\n",
       "      <td>2.475533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. White</td>\n",
       "      <td>32</td>\n",
       "      <td>1.842257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr. Green</td>\n",
       "      <td>28</td>\n",
       "      <td>1.611975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr. Jones</td>\n",
       "      <td>23</td>\n",
       "      <td>1.324122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Smith</td>\n",
       "      <td>22</td>\n",
       "      <td>1.266552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mr. Black</td>\n",
       "      <td>18</td>\n",
       "      <td>1.036269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mr. Taylor</td>\n",
       "      <td>12</td>\n",
       "      <td>0.690846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mr. Li</td>\n",
       "      <td>10</td>\n",
       "      <td>0.575705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mr. Johnson</td>\n",
       "      <td>10</td>\n",
       "      <td>0.575705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mr. Parsons</td>\n",
       "      <td>9</td>\n",
       "      <td>0.518135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mr. Lee</td>\n",
       "      <td>9</td>\n",
       "      <td>0.518135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mr. Zhang</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mr. Wang</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bank of</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mr. Sun</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mrs. Brown</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Miao Ping</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Allied Irish</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sarah O</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Trans Pacific</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>L. A</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dr. Smith</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mrs. White</td>\n",
       "      <td>6</td>\n",
       "      <td>0.345423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mr. Harrison</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mr. Liu</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mr. Roberts</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mr. James</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Happy Birthday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mr. Lin</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cuervo Gold</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Whole Foods</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ms. Wang</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Mr. John</td>\n",
       "      <td>5</td>\n",
       "      <td>0.287853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mr. Sandals</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mr. Anderson</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Janet Jackson</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ms. Green</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mr. Emory</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Mrs. Vale</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Love Me</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Atlantic Trading</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Visual C</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>San Felice</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Margaret Seabrook</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Miss Liu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mrs. Green</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>excuse me</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mr. Zu</td>\n",
       "      <td>4</td>\n",
       "      <td>0.230282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  count     ratio\n",
       "0           Mr. Smith     49  2.820956\n",
       "1           Mr. Brown     43  2.475533\n",
       "2           Mr. White     32  1.842257\n",
       "3           Mr. Green     28  1.611975\n",
       "4           Mr. Jones     23  1.324122\n",
       "5          Mrs. Smith     22  1.266552\n",
       "6           Mr. Black     18  1.036269\n",
       "7          Mr. Taylor     12  0.690846\n",
       "8              Mr. Li     10  0.575705\n",
       "9         Mr. Johnson     10  0.575705\n",
       "10        Mr. Parsons      9  0.518135\n",
       "11            Mr. Lee      9  0.518135\n",
       "12          Mr. Zhang      7  0.402994\n",
       "13           Mr. Wang      7  0.402994\n",
       "14            Bank of      7  0.402994\n",
       "15            Mr. Sun      7  0.402994\n",
       "16         Mrs. Brown      7  0.402994\n",
       "17          Miao Ping      7  0.402994\n",
       "18       Allied Irish      7  0.402994\n",
       "19            Sarah O      6  0.345423\n",
       "20      Trans Pacific      6  0.345423\n",
       "21               L. A      6  0.345423\n",
       "22          Dr. Smith      6  0.345423\n",
       "23         Mrs. White      6  0.345423\n",
       "24       Mr. Harrison      5  0.287853\n",
       "25            Mr. Liu      5  0.287853\n",
       "26        Mr. Roberts      5  0.287853\n",
       "27          Mr. James      5  0.287853\n",
       "28     Happy Birthday      5  0.287853\n",
       "29            Mr. Lin      5  0.287853\n",
       "30        Cuervo Gold      5  0.287853\n",
       "31        Whole Foods      5  0.287853\n",
       "32           Ms. Wang      5  0.287853\n",
       "33           Mr. John      5  0.287853\n",
       "34        Mr. Sandals      4  0.230282\n",
       "35       Mr. Anderson      4  0.230282\n",
       "36      Janet Jackson      4  0.230282\n",
       "37          Ms. Green      4  0.230282\n",
       "38          Mr. Emory      4  0.230282\n",
       "39          Mrs. Vale      4  0.230282\n",
       "40            Love Me      4  0.230282\n",
       "41   Atlantic Trading      4  0.230282\n",
       "42           Visual C      4  0.230282\n",
       "43         San Felice      4  0.230282\n",
       "44      San Francisco      4  0.230282\n",
       "45  Margaret Seabrook      4  0.230282\n",
       "46           Miss Liu      4  0.230282\n",
       "47         Mrs. Green      4  0.230282\n",
       "48          excuse me      4  0.230282\n",
       "49             Mr. Zu      4  0.230282"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "all_dialogues = pd.concat([train_df['dialogue'], val_df['dialogue'], test_df['dialogue']])\n",
    "all_english = []\n",
    "\n",
    "# 반복문을 돌며 영어 단어들을 수집하여 all_english 에 추가\n",
    "for text in tqdm(all_dialogues):\n",
    "    two_word_phrases = re.findall(r'\\b(?:[a-zA-Z]+\\.?\\s+[a-zA-Z]+)\\b', text, re.IGNORECASE)\n",
    "    all_english.extend(two_word_phrases)\n",
    "eng_counts = Counter(all_english)\n",
    "\n",
    "len_eng_counts = sum(eng_counts.values())\n",
    "word_counts_df = []\n",
    "for eng_word, count in eng_counts.items():\n",
    "    word_counts_df.append([eng_word, count, count/len_eng_counts*100])\n",
    "word_counts_df = pd.DataFrame(\n",
    "    data=word_counts_df,\n",
    "    columns=['word', 'count', 'ratio']\n",
    ")\n",
    "word_counts_df = word_counts_df.sort_values('count', ascending=False)\n",
    "word_counts_df = word_counts_df.reset_index(drop=True)\n",
    "print(word_counts_df.shape[0])\n",
    "word_counts_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97239d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "#Person1#: 스미스 씨, 질문 하나 해도 될까요?\n",
      "#Person2#: 네, 말씀하세요.\n",
      "#Person1#: 꽤 오랫동안 'I'm sorry'랑 'excuse me'라는 두 표현의 차이가 헷갈렸어요. 중국어로 번역하면 같은 의미처럼 보이거든요. 어떻게 올바르게 사용하는지 설명해 주실 수 있을까요?\n",
      "#Person2#: 좋아요, 사실 이 둘 사이에는 큰 차이가 있어요. 몇 가지 예를 들어 설명해 드릴게요. 누군가와 이야기 중에 대화를 끝내거나 자리를 비울 때 공손하게 말할 수 있는 표현이에요.\n",
      "#Person1#: 그게 'I'm sorry'인가요?\n",
      "#Person2#: 아니요, 'excuse me' 혹은 'excuse me, please'라고 말해요. 그리고 다른 사람의 말을 끊을 때도 'excuse me'를 사용해요...\n",
      "#Person1#: 실례합니다, 스미스 씨.\n",
      "#Person2#: 아주 잘하셨어요, 양 씨. 무슨 말씀하시려고 했나요?\n",
      "#Person1#: 만약 우연히 누군가에게 부딪히거나 지나가려 할 때는 'sorry'나 'I'm so sorry'라고 해야 하나요?\n",
      "#Person2#: 정말 빠르게 배우시네요.\n",
      "양 씨는 'I'm sorry'와 'excuse me'라는 표현의 차이에 대해 혼란스러워 했습니다. 스미스 씨는 이 두 표현을 어떻게 올바르게 사용하는지 설명합니다.\n"
     ]
    }
   ],
   "source": [
    "contain_df = train_df[train_df['dialogue'].str.contains('excuse me')]\n",
    "print(len(contain_df))\n",
    "print(contain_df['dialogue'].values[0])\n",
    "print(contain_df['summary'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4af557b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m contain_df = test_df[test_df[\u001b[33m'\u001b[39m\u001b[33mdialogue\u001b[39m\u001b[33m'\u001b[39m].str.contains(\u001b[33m'\u001b[39m\u001b[33mexcuse me\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(contain_df))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcontain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdialogue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mIndexError\u001b[39m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "contain_df = test_df[test_df['dialogue'].str.contains('excuse me')]\n",
    "print(len(contain_df))\n",
    "print(contain_df['dialogue'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49c87754",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df.to_csv(os.path.join(project_dir,'data','01_two_words_english_counts.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fe974",
   "metadata": {},
   "source": [
    "- 1개 영단어 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d09eff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13455/13455 [00:00<00:00, 65675.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr</td>\n",
       "      <td>797</td>\n",
       "      <td>6.439884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'</td>\n",
       "      <td>484</td>\n",
       "      <td>3.910795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TV</td>\n",
       "      <td>249</td>\n",
       "      <td>2.011959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhoneNumber</td>\n",
       "      <td>238</td>\n",
       "      <td>1.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mary</td>\n",
       "      <td>202</td>\n",
       "      <td>1.632191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smith</td>\n",
       "      <td>152</td>\n",
       "      <td>1.228184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>150</td>\n",
       "      <td>1.212023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom</td>\n",
       "      <td>142</td>\n",
       "      <td>1.147382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>John</td>\n",
       "      <td>130</td>\n",
       "      <td>1.050420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bob</td>\n",
       "      <td>104</td>\n",
       "      <td>0.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Miss</td>\n",
       "      <td>99</td>\n",
       "      <td>0.799935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jack</td>\n",
       "      <td>98</td>\n",
       "      <td>0.791855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr</td>\n",
       "      <td>97</td>\n",
       "      <td>0.783775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Address</td>\n",
       "      <td>92</td>\n",
       "      <td>0.743374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>89</td>\n",
       "      <td>0.719134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jane</td>\n",
       "      <td>88</td>\n",
       "      <td>0.711054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ms</td>\n",
       "      <td>88</td>\n",
       "      <td>0.711054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mike</td>\n",
       "      <td>88</td>\n",
       "      <td>0.711054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>David</td>\n",
       "      <td>80</td>\n",
       "      <td>0.646412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bill</td>\n",
       "      <td>78</td>\n",
       "      <td>0.630252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>L</td>\n",
       "      <td>76</td>\n",
       "      <td>0.614092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brown</td>\n",
       "      <td>74</td>\n",
       "      <td>0.597931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Susan</td>\n",
       "      <td>69</td>\n",
       "      <td>0.557531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Steven</td>\n",
       "      <td>67</td>\n",
       "      <td>0.541370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Jim</td>\n",
       "      <td>65</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C</td>\n",
       "      <td>65</td>\n",
       "      <td>0.525210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Li</td>\n",
       "      <td>64</td>\n",
       "      <td>0.517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>D</td>\n",
       "      <td>63</td>\n",
       "      <td>0.509050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Green</td>\n",
       "      <td>62</td>\n",
       "      <td>0.500970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>White</td>\n",
       "      <td>56</td>\n",
       "      <td>0.452489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wang</td>\n",
       "      <td>55</td>\n",
       "      <td>0.444409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I</td>\n",
       "      <td>50</td>\n",
       "      <td>0.404008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mark</td>\n",
       "      <td>48</td>\n",
       "      <td>0.387847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>E</td>\n",
       "      <td>47</td>\n",
       "      <td>0.379767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Alice</td>\n",
       "      <td>44</td>\n",
       "      <td>0.355527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sam</td>\n",
       "      <td>44</td>\n",
       "      <td>0.355527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Peter</td>\n",
       "      <td>43</td>\n",
       "      <td>0.347447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CD</td>\n",
       "      <td>43</td>\n",
       "      <td>0.347447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>43</td>\n",
       "      <td>0.347447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Paul</td>\n",
       "      <td>42</td>\n",
       "      <td>0.339367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The</td>\n",
       "      <td>40</td>\n",
       "      <td>0.323206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ann</td>\n",
       "      <td>40</td>\n",
       "      <td>0.323206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ABC</td>\n",
       "      <td>39</td>\n",
       "      <td>0.315126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>James</td>\n",
       "      <td>39</td>\n",
       "      <td>0.315126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>N</td>\n",
       "      <td>38</td>\n",
       "      <td>0.307046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Tim</td>\n",
       "      <td>37</td>\n",
       "      <td>0.298966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>37</td>\n",
       "      <td>0.298966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>35</td>\n",
       "      <td>0.282805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Jones</td>\n",
       "      <td>34</td>\n",
       "      <td>0.274725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Kate</td>\n",
       "      <td>34</td>\n",
       "      <td>0.274725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  count     ratio\n",
       "0            Mr    797  6.439884\n",
       "1             '    484  3.910795\n",
       "2            TV    249  2.011959\n",
       "3   PhoneNumber    238  1.923077\n",
       "4          Mary    202  1.632191\n",
       "5         Smith    152  1.228184\n",
       "6           Mrs    150  1.212023\n",
       "7           Tom    142  1.147382\n",
       "8          John    130  1.050420\n",
       "9           Bob    104  0.840336\n",
       "10         Miss     99  0.799935\n",
       "11         Jack     98  0.791855\n",
       "12           Dr     97  0.783775\n",
       "13      Address     92  0.743374\n",
       "14            A     89  0.719134\n",
       "15         Jane     88  0.711054\n",
       "16           Ms     88  0.711054\n",
       "17         Mike     88  0.711054\n",
       "18        David     80  0.646412\n",
       "19         Bill     78  0.630252\n",
       "20            L     76  0.614092\n",
       "21        Brown     74  0.597931\n",
       "22        Susan     69  0.557531\n",
       "23       Steven     67  0.541370\n",
       "24          Jim     65  0.525210\n",
       "25            C     65  0.525210\n",
       "26           Li     64  0.517130\n",
       "27            D     63  0.509050\n",
       "28        Green     62  0.500970\n",
       "29        White     56  0.452489\n",
       "30         Wang     55  0.444409\n",
       "31            I     50  0.404008\n",
       "32         Mark     48  0.387847\n",
       "33            E     47  0.379767\n",
       "34        Alice     44  0.355527\n",
       "35          Sam     44  0.355527\n",
       "36        Peter     43  0.347447\n",
       "37           CD     43  0.347447\n",
       "38        Jenny     43  0.347447\n",
       "39         Paul     42  0.339367\n",
       "40          The     40  0.323206\n",
       "41          Ann     40  0.323206\n",
       "42          ABC     39  0.315126\n",
       "43        James     39  0.315126\n",
       "44            N     38  0.307046\n",
       "45          Tim     37  0.298966\n",
       "46        Sarah     37  0.298966\n",
       "47      Johnson     35  0.282805\n",
       "48        Jones     34  0.274725\n",
       "49         Kate     34  0.274725"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "all_dialogues = pd.concat([train_df['dialogue'], val_df['dialogue'], test_df['dialogue']])\n",
    "all_english = []\n",
    "\n",
    "# 반복문을 돌며 영어 단어들을 수집하여 all_english 에 추가\n",
    "for text in tqdm(all_dialogues):\n",
    "    all_potential_words = re.findall(r'\\b[a-zA-Z\\']+\\b', text, re.IGNORECASE)\n",
    "    all_english.extend(all_potential_words)\n",
    "eng_counts = Counter(all_english)\n",
    "\n",
    "len_eng_counts = sum(eng_counts.values())\n",
    "word_counts_df = []\n",
    "for eng_word, count in eng_counts.items():\n",
    "    word_counts_df.append([eng_word, count, count/len_eng_counts*100])\n",
    "word_counts_df = pd.DataFrame(\n",
    "    data=word_counts_df,\n",
    "    columns=['word', 'count', 'ratio']\n",
    ")\n",
    "word_counts_df = word_counts_df.sort_values('count', ascending=False)\n",
    "word_counts_df = word_counts_df.reset_index(drop=True)\n",
    "print(word_counts_df.shape[0])\n",
    "word_counts_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a7be7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df.to_csv(os.path.join(project_dir,'data','01_one_words_english_counts.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8666c",
   "metadata": {},
   "source": [
    "- 1개 이상 연속된 영단어 모두 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "124caed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13455/13455 [00:00<00:00, 44370.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>... Vanilla Ice</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>'Ice Ice Baby'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Mr. Liang</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>. DKNY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>Grant</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>PHS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>Mrs. Word</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>. Stanley</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>Sterling</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>Professor Wood</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>Eliza</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Jimmy Fox</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>Mr. Fox.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>. Mr. Fox</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>. John Sampson</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>Martha Bicycle Club</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>mountain lake cycle tour</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>Ottawa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>Ripken</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>. Jess</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>Jess</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>... Jess</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>Ford Pinto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>Ford Focus</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>. Ballam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>Betsy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>. Tang</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>Youth International Travel Agency</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>. Atlanta Georgia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>Danny's</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>CBC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>Golden Country Time</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>'Fast Food Nation'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>. FICA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>Gene</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>Li Lan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>. Miss Jenkins</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>Miss Jenkins</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>Mrs. Robinson.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>. Johnny</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>S M I T H</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>Steven Kayne</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>. Kayne</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>Kayne</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>. Mr. Murray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>Gian Luca Donatelli</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>Marty</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>'Harold Dickson'</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>Cal Ripken</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   word  count     ratio\n",
       "4684                    ... Vanilla Ice      1  0.000335\n",
       "4685                     'Ice Ice Baby'      1  0.000335\n",
       "4686                          Mr. Liang      1  0.000335\n",
       "4687                             . DKNY      1  0.000335\n",
       "4688                              Grant      1  0.000335\n",
       "4689                                PHS      1  0.000335\n",
       "4690                          Mrs. Word      1  0.000335\n",
       "4691                          . Stanley      1  0.000335\n",
       "4692                           Sterling      1  0.000335\n",
       "4693                     Professor Wood      1  0.000335\n",
       "4694                              Eliza      1  0.000335\n",
       "4695                          Jimmy Fox      1  0.000335\n",
       "4696                           Mr. Fox.      1  0.000335\n",
       "4697                          . Mr. Fox      1  0.000335\n",
       "4698                     . John Sampson      1  0.000335\n",
       "4699                Martha Bicycle Club      1  0.000335\n",
       "4700           mountain lake cycle tour      1  0.000335\n",
       "4701                             Ottawa      1  0.000335\n",
       "4702                             Ripken      1  0.000335\n",
       "4703                             . Jess      1  0.000335\n",
       "4704                               Jess      1  0.000335\n",
       "4705                           ... Jess      1  0.000335\n",
       "4706                         Ford Pinto      1  0.000335\n",
       "4707                         Ford Focus      1  0.000335\n",
       "4708                           . Ballam      1  0.000335\n",
       "4709                              Betsy      1  0.000335\n",
       "4710                             . Tang      1  0.000335\n",
       "4711  Youth International Travel Agency      1  0.000335\n",
       "4712                  . Atlanta Georgia      1  0.000335\n",
       "4713                            Danny's      1  0.000335\n",
       "4714                                CBC      1  0.000335\n",
       "4715                Golden Country Time      1  0.000335\n",
       "4716                 'Fast Food Nation'      1  0.000335\n",
       "4717                             . FICA      1  0.000335\n",
       "4718                               Gene      1  0.000335\n",
       "4719                             Morgan      1  0.000335\n",
       "4720                             Li Lan      1  0.000335\n",
       "4721                     . Miss Jenkins      1  0.000335\n",
       "4722                       Miss Jenkins      1  0.000335\n",
       "4723                     Mrs. Robinson.      1  0.000335\n",
       "4724                           . Johnny      1  0.000335\n",
       "4725                          S M I T H      1  0.000335\n",
       "4726                       Steven Kayne      1  0.000335\n",
       "4727                            . Kayne      1  0.000335\n",
       "4728                              Kayne      1  0.000335\n",
       "4729                       . Mr. Murray      1  0.000335\n",
       "4730                Gian Luca Donatelli      1  0.000335\n",
       "4731                              Marty      1  0.000335\n",
       "4732                   'Harold Dickson'      1  0.000335\n",
       "4733                         Cal Ripken      1  0.000335"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import regex\n",
    "\n",
    "all_dialogues = pd.concat([train_df['dialogue'], val_df['dialogue'], test_df['dialogue']])\n",
    "all_english = []\n",
    "\n",
    "# 반복문을 돌며 영어 단어들을 수집하여 all_english 에 추가\n",
    "for text in tqdm(all_dialogues):\n",
    "    # two_word_phrases = re.findall(r'\\b[a-zA-Z\\']+\\b(?:[^\\w\\s]*\\s*\\b[a-zA-Z\\']+\\b){2,}', text, re.IGNORECASE)\n",
    "    every_word_phrases = regex.findall(r\"[\\p{Latin}\\.']+(?: [\\p{Latin}\\.']+)*\", text, re.IGNORECASE)\n",
    "    for eng_word in every_word_phrases:\n",
    "        if eng_word.endswith('.'): # 영단어가 마침표로 끝나면 마침표만 제거\n",
    "            eng_word = eng_word.replace('.','')\n",
    "        \n",
    "    all_english.extend(every_word_phrases)\n",
    "eng_counts = Counter(all_english)\n",
    "\n",
    "len_eng_counts = sum(eng_counts.values())\n",
    "word_counts_df = []\n",
    "for eng_word, count in eng_counts.items():\n",
    "    word_counts_df.append([eng_word, count, count/len_eng_counts*100])\n",
    "word_counts_df = pd.DataFrame(\n",
    "    data=word_counts_df,\n",
    "    columns=['word', 'count', 'ratio']\n",
    ")\n",
    "word_counts_df = word_counts_df.sort_values('count', ascending=False)\n",
    "word_counts_df = word_counts_df.reset_index(drop=True)\n",
    "print(word_counts_df.shape[0])\n",
    "word_counts_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a9a66691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "#Person1#: 안녕, Susan. 잠깐 시간 있어? 내 급여에 대해 궁금한 게 좀 있어서. \n",
      "#Person2#: 물론이지, Emily. 앉아서 얘기해. \n",
      "#Person1#: 음, 여기 미국에서 받은 첫 급여인데 이해가 안 가는 부분이 몇 가지 있어. 우선, FICA랑 SUI 세금이 뭐고, 왜 Medicare랑 건강 보험 계획 둘 다에서 공제가 되는 거야? \n",
      "#Person2#: 좋아, 급여 명세서의 맨 위부터 시작하자. 이 숫자는 네 총 급여를 나타내. 그다음에는 일련의 공제가 있어. 먼저 연방 공제부터 볼게. FICA는 Federal Insurance Contribution Act의 약자야. 이게 네 연방 소득세야. 그리고 사회보장세와 Medicare가 있는데, 이 두 개는 네가 은퇴하거나 일을 못 하게 됐을 때를 지원하기 위한 연방 프로그램이야. \n",
      "#Person1#: 아, 알겠어. 그러면 Medicare는 내가 지금 쓸 수 있는 건강 보험은 아니네. \n",
      "#Person2#: 맞아. 연방 공제 아래엔 주 공제가 있어. 주 소득세가 있고, 네가 물어본 SUI 세금은 주에서 설립한 실업 및 장애 기금에 기여하는 건데, 굉장히 적은 금액이 공제된다는 걸 알 수 있어. \n",
      "#Person1#: 그래, 그거에 1달러 50센트 내는 건 별로 상관없어. 그러니까 주 레벨이랑 연방 레벨, 이렇게 두 가지의 별도 소득세가 있는 거네? \n",
      "#Person2#: 맞아. 모든 주가 소득세가 있는 건 아니야. 어떤 주는 더 높은 재산세나 판매세를 사용하지. \n",
      "#Person1#: 알겠어. 그 외의 것들은 내가 스스로 해결할 수 있을 것 같아. 건강 보험이랑 내 401(k) 공제는 꽤 명확해. 도와줘서 고마워, Susan. \n",
      "#Person2#: 별말을 다해! 그런 공제들이 정말 쌓이고, 아무도 자신의 순 급여가 원하는 만큼 높지 않으니까. 설명이 필요하다니 이해돼. \n",
      "#Person1#: 그래, 영국도 똑같은 것 같아. 단지 내가 신경을 별로 안 썼던 것뿐이지. 나중에 봐!\n"
     ]
    }
   ],
   "source": [
    "contain_df = test_df[test_df['dialogue'].str.contains(\"FICA\")]\n",
    "print(len(contain_df))\n",
    "print(contain_df['dialogue'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05518e",
   "metadata": {},
   "source": [
    "#### 영단어는 항상 Summary에 존재하는가?\n",
    "- dialogue와 summary에 모두 존재하는 영단어만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34aeef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'count', 'ratio'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_word_engs = pd.read_csv(os.path.join(project_dir, 'data', \"01_two_words_english_counts.csv\"))\n",
    "two_word_engs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb84dc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12956, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([train_df, val_df], axis=0)\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db107eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2e58589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"sdfj 'My Heart Will Go On'.\", \"'bon appétit'\", 'the', 'Karren', 'Jessica', 'Mr. Smith', \"Jack O' Nill\"]\n"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "\n",
    "# 라틴 문자와 작은따옴표, 마침표를 포함하는 연속된 단어와 구문을 추출합니다.\n",
    "regex_pattern = r\"[\\p{Latin}\\.']+(?: [\\p{Latin}\\.']+)*\"\n",
    "\n",
    "text_data = \"앙녕ㅎㄴ아ㅓㄹ sdfj 'My Heart Will Go On'., 'bon appétit', the, Karren, Jessica, Mr. Smith, Jack O' Nill\"\n",
    "matches = regex.findall(regex_pattern, text_data)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050fd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac895c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
