{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642f7ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bdc4f05d6c4c3bb4e458e490212dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13c755ec281450397111b6fa325fba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef693f7cfe0145fa889780ca8a8be40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig, AutoModelForSeq2SeqLM, AutoConfig\n",
    "\n",
    "'''\n",
    "T5 계열 중 사용 가능한 모델 예시\n",
    "- csebuetnlp/mT5_multilingual_XLSum\n",
    "- eenzeenee/t5-base-korean-summarization\n",
    "...\n",
    "\n",
    "BART 계열 중 사용 가능한 모델 예시\n",
    "- EbanLee/kobart-summary-v3\n",
    "- digit82/kobart-summarization\n",
    "...\n",
    "'''\n",
    "\n",
    "model_name = \"eenzeenee/t5-small-korean-summarization\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa9cb0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9b815e0c154749bbb5eb627ae6519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/780 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "128\n",
      "0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(model_name)\n",
    "print(f\"{model_config.num_beams}\\n\"\n",
    "f\"{model_config.max_length}\\n\"\n",
    "f\"{model_config.no_repeat_ngram_size}\\n\"\n",
    "f\"{model_config.length_penalty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fbf03ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ìķĪëħķ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"안녕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac036c",
   "metadata": {},
   "source": [
    "- ⚠️ config의 inference/remove_tokens에는 Special_token을 추가하지 전에 토크나이저가 기본적으로 갖고 있는 special tokens를 설정해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd15b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['</s>', '<pad>', '<pad>', '<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\n"
     ]
    }
   ],
   "source": [
    "import collections.abc\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if isinstance(el, collections.abc.Iterable) and not isinstance(el, (str, bytes)):\n",
    "            yield from flatten(el)\n",
    "        else:\n",
    "            yield el\n",
    "try:\n",
    "    remove_tokens = list(flatten(tokenizer.special_tokens_map.values()))\n",
    "except:\n",
    "    remove_tokens = []\n",
    "print(remove_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7941ed",
   "metadata": {},
   "source": [
    "- ⚠️ 만약 bos_token이 None이라면 토크나이저에 맞는 처리를 해야 한다.\n",
    "    - T5 계열 모델의 토크나이저는 bos_token을 사용하지 않는다. 그냥 None으로 놔두면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28bf67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    BOS token id : None,\n",
      "    BOS : None,\n",
      "    EOS : </s>,\n",
      "    PAD : <pad>\n",
      "    Special_tokens : {'eos_token': '</s>', 'unk_token': '<pad>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']},\n",
      "    Tokenizer's max_model_input_sizes : 128\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    BART Embedding Layer: {model.get_encoder().embed_tokens}, {model.get_encoder().embed_positions}\n",
    "    tokenizer의 encoder_max_len은 {model.get_encoder().embed_positions.num_embeddings} 이하여야 한다.\n",
    "\n",
    "    BART Decoder Layer: {model.get_decoder().embed_tokens}, {model.get_decoder().embed_positions}\n",
    "    tokenizer의 decoder_max_len은 {model.get_decoder().embed_positions.num_embeddings} 이하여야 한다.\n",
    "'''\n",
    "\n",
    "# from pprint import pprint\n",
    "print(f'''\n",
    "    BOS token id : {tokenizer.bos_token_id},\n",
    "    BOS : {tokenizer.bos_token},\n",
    "    EOS : {tokenizer.eos_token},\n",
    "    PAD : {tokenizer.pad_token}\n",
    "    Special_tokens : {tokenizer.special_tokens_map},\n",
    "    Tokenizer's max_model_input_sizes : {tokenizer.model_max_length}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a9cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "project_dir = \"/data/ephemeral/home/nlp-5/auto1p/\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\n",
    "    project_dir\n",
    ")\n",
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514c6d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08020735\n"
     ]
    }
   ],
   "source": [
    "current_time = get_current_time()\n",
    "concept = \"t5\" # 실험 컨셉을 작성. output 디렉토리 이름 및 config 파일 이름 설정 시 반영됨.\n",
    "output_dir = f\"./outputs/exp_{concept}_{current_time}\"\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d47f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.eda_length import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f6ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_eval_log_steps = 1 # save_step은 eval, log step의 배수여야 한다. 같이 맞춰주는 것이 편하다.\n",
    "train_batch_size = 8\n",
    "inference_batch_size = 8 # eval batch size 도 동일하게 설정됨\n",
    "encoder_max_len = 1300 # 모델의 encoder input length 보다는 작게 설정해야 함. (확인하는 방법이 모델마다 다름;;)\n",
    "decoder_max_len = 170 # inference max length 도 동일하게 설정됨 > 170 이하를 추천."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13d51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"./data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": model_name, # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": output_dir, # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "        \"train_data\": \"train.csv\", # 학습 데이터 파일을 설정한다. data_path 폴더 안에 존재해야 한다.\n",
    "        \"val_data\": \"dev.csv\",\n",
    "        \"test_data\": \"test.csv\", # 추론 데이터 파일을 설정한다. 추론 데이터에 topic이나 ner을 추가할 경우에 대비.\n",
    "        \"eval_tokenizer\": \"upstage/solar-pro2-tokenizer\",\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": encoder_max_len,\n",
    "        \"decoder_max_len\": decoder_max_len,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": [ '#Person1#', '#Person2#', '#Person3#', '#Person4#',\n",
    "            '#Person5#', '#Person6#', '#Person7#',\n",
    "            '#PhoneNumber#', '#Address#', '#DateOfBirth#','#PassportNumber#','#SSN#','#CardNumber#','#CarNumber#','#Email#',\n",
    "            # '#Topic#','#Dialogue#','#SEP#',\n",
    "        ]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": 42,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"overwrite_output_dir\": False,\n",
    "\n",
    "        \"save_total_limit\": 1,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"save_steps\": save_eval_log_steps,\n",
    "\n",
    "        \"logging_dir\": output_dir,\n",
    "        \"logging_steps\": save_eval_log_steps,\n",
    "\n",
    "        \"num_train_epochs\": 5,\n",
    "        \"per_device_train_batch_size\": train_batch_size,\n",
    "        \"remove_unused_columns\": True,\n",
    "        \"fp16\": False, # float16 사용 메모리 절약, But 정밀도 문제 존재 > 구형 GPU에서 사용\n",
    "        \"bf16\": True, # float16 사용 메모리 절약, 정밀도 문제 개선 > 30/40,... 등 최신 GPU 가능\n",
    "        \"dataloader_drop_last\": False,\n",
    "        \"group_by_length\": True,\n",
    "        \n",
    "        \"gradient_checkpointing\": True,\n",
    "        \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False, 'use_cache': False},\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"torch_empty_cache_steps\": 1,\n",
    "        \"dataloader_num_workers\": 8,\n",
    "\n",
    "        \"per_device_eval_batch_size\": inference_batch_size,\n",
    "        \"evaluation_strategy\": 'steps',\n",
    "        \"eval_steps\": save_eval_log_steps,\n",
    "        \n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": decoder_max_len,\n",
    "        \n",
    "        # Callbacks\n",
    "        \"early_stopping_patience\": 2,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "\n",
    "        # Optimizer\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"warmup_steps\": 10,\n",
    "        \"weight_decay\": 1e-3,\n",
    "        \"num_cycles\": 1,\n",
    "\n",
    "        \"report_to\": \"none\", # 학습 과정을 어느 백엔드에 저장할 것인지. \"none\" 설정 시 wandb 미사용. \"wandb\" 설정 시 사용.\n",
    "\n",
    "        # PEFT\n",
    "        \"LoRA\": False,\n",
    "        \"QLoRA\": False,\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"skiersong\", # 팀 실험 시 organization 이름\n",
    "        \"project\": \"nlp-5-upgrade\",\n",
    "        \"name\": f\"a_base_{current_time}\", # 개별 실험 이름\n",
    "        # \"group\": \"\", # 유사한 실험들은 같은 그룹으로 설정\n",
    "        \"notes\": \"AutoModel baseline\", # 실험에 대한 추가 설명\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_dir\": os.path.join(output_dir, 'best'), # 파인튜닝이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": os.path.join(output_dir, f\"submission_{current_time}.csv\"), # 제출할 csv 파일 저장 경로\n",
    "        \"no_repeat_ngram_size\": 2, # \n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": decoder_max_len,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : inference_batch_size,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": remove_tokens,\n",
    "        \"length_penalty\": 1.2 # > 1로 설정하면 짧은 문장을 선호하도록 페널티를 강화, 1보다 작은 값을 주면 긴 생성문을 선호하게 된다.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616c2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': './data/',\n",
      "             'eval_tokenizer': 'upstage/solar-pro2-tokenizer',\n",
      "             'model_name': 'eenzeenee/t5-base-korean-summarization',\n",
      "             'output_dir': './outputs/exp_t5_08020735',\n",
      "             'test_data': 'test.csv',\n",
      "             'train_data': 'train.csv',\n",
      "             'val_data': 'dev.csv'},\n",
      " 'inference': {'batch_size': 8,\n",
      "               'ckt_dir': './outputs/exp_t5_08020735/best',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 170,\n",
      "               'length_penalty': 1.2,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['</s>',\n",
      "                                 '<pad>',\n",
      "                                 '<pad>',\n",
      "                                 ['<extra_id_0>',\n",
      "                                  '<extra_id_1>',\n",
      "                                  '<extra_id_2>',\n",
      "                                  '<extra_id_3>',\n",
      "                                  '<extra_id_4>',\n",
      "                                  '<extra_id_5>',\n",
      "                                  '<extra_id_6>',\n",
      "                                  '<extra_id_7>',\n",
      "                                  '<extra_id_8>',\n",
      "                                  '<extra_id_9>',\n",
      "                                  '<extra_id_10>',\n",
      "                                  '<extra_id_11>',\n",
      "                                  '<extra_id_12>',\n",
      "                                  '<extra_id_13>',\n",
      "                                  '<extra_id_14>',\n",
      "                                  '<extra_id_15>',\n",
      "                                  '<extra_id_16>',\n",
      "                                  '<extra_id_17>',\n",
      "                                  '<extra_id_18>',\n",
      "                                  '<extra_id_19>',\n",
      "                                  '<extra_id_20>',\n",
      "                                  '<extra_id_21>',\n",
      "                                  '<extra_id_22>',\n",
      "                                  '<extra_id_23>',\n",
      "                                  '<extra_id_24>',\n",
      "                                  '<extra_id_25>',\n",
      "                                  '<extra_id_26>',\n",
      "                                  '<extra_id_27>',\n",
      "                                  '<extra_id_28>',\n",
      "                                  '<extra_id_29>',\n",
      "                                  '<extra_id_30>',\n",
      "                                  '<extra_id_31>',\n",
      "                                  '<extra_id_32>',\n",
      "                                  '<extra_id_33>',\n",
      "                                  '<extra_id_34>',\n",
      "                                  '<extra_id_35>',\n",
      "                                  '<extra_id_36>',\n",
      "                                  '<extra_id_37>',\n",
      "                                  '<extra_id_38>',\n",
      "                                  '<extra_id_39>',\n",
      "                                  '<extra_id_40>',\n",
      "                                  '<extra_id_41>',\n",
      "                                  '<extra_id_42>',\n",
      "                                  '<extra_id_43>',\n",
      "                                  '<extra_id_44>',\n",
      "                                  '<extra_id_45>',\n",
      "                                  '<extra_id_46>',\n",
      "                                  '<extra_id_47>',\n",
      "                                  '<extra_id_48>',\n",
      "                                  '<extra_id_49>',\n",
      "                                  '<extra_id_50>',\n",
      "                                  '<extra_id_51>',\n",
      "                                  '<extra_id_52>',\n",
      "                                  '<extra_id_53>',\n",
      "                                  '<extra_id_54>',\n",
      "                                  '<extra_id_55>',\n",
      "                                  '<extra_id_56>',\n",
      "                                  '<extra_id_57>',\n",
      "                                  '<extra_id_58>',\n",
      "                                  '<extra_id_59>',\n",
      "                                  '<extra_id_60>',\n",
      "                                  '<extra_id_61>',\n",
      "                                  '<extra_id_62>',\n",
      "                                  '<extra_id_63>',\n",
      "                                  '<extra_id_64>',\n",
      "                                  '<extra_id_65>',\n",
      "                                  '<extra_id_66>',\n",
      "                                  '<extra_id_67>',\n",
      "                                  '<extra_id_68>',\n",
      "                                  '<extra_id_69>',\n",
      "                                  '<extra_id_70>',\n",
      "                                  '<extra_id_71>',\n",
      "                                  '<extra_id_72>',\n",
      "                                  '<extra_id_73>',\n",
      "                                  '<extra_id_74>',\n",
      "                                  '<extra_id_75>',\n",
      "                                  '<extra_id_76>',\n",
      "                                  '<extra_id_77>',\n",
      "                                  '<extra_id_78>',\n",
      "                                  '<extra_id_79>',\n",
      "                                  '<extra_id_80>',\n",
      "                                  '<extra_id_81>',\n",
      "                                  '<extra_id_82>',\n",
      "                                  '<extra_id_83>',\n",
      "                                  '<extra_id_84>',\n",
      "                                  '<extra_id_85>',\n",
      "                                  '<extra_id_86>',\n",
      "                                  '<extra_id_87>',\n",
      "                                  '<extra_id_88>',\n",
      "                                  '<extra_id_89>',\n",
      "                                  '<extra_id_90>',\n",
      "                                  '<extra_id_91>',\n",
      "                                  '<extra_id_92>',\n",
      "                                  '<extra_id_93>',\n",
      "                                  '<extra_id_94>',\n",
      "                                  '<extra_id_95>',\n",
      "                                  '<extra_id_96>',\n",
      "                                  '<extra_id_97>',\n",
      "                                  '<extra_id_98>',\n",
      "                                  '<extra_id_99>']],\n",
      "               'result_path': './outputs/exp_t5_08020735/submission_08020735.csv'},\n",
      " 'tokenizer': {'bos_token': 'None',\n",
      "               'decoder_max_len': 170,\n",
      "               'encoder_max_len': 1300,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#Person4#',\n",
      "                                  '#Person5#',\n",
      "                                  '#Person6#',\n",
      "                                  '#Person7#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#Email#']},\n",
      " 'training': {'LoRA': False,\n",
      "              'QLoRA': False,\n",
      "              'bf16': True,\n",
      "              'dataloader_drop_last': False,\n",
      "              'dataloader_num_workers': 8,\n",
      "              'early_stopping_patience': 2,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'eval_steps': 1,\n",
      "              'evaluation_strategy': 'steps',\n",
      "              'fp16': False,\n",
      "              'generation_max_length': 170,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'gradient_checkpointing': True,\n",
      "              'gradient_checkpointing_kwargs': {'use_cache': False,\n",
      "                                                'use_reentrant': False},\n",
      "              'group_by_length': True,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './outputs/exp_t5_08020735',\n",
      "              'logging_steps': 1,\n",
      "              'num_cycles': 1,\n",
      "              'num_train_epochs': 5,\n",
      "              'output_dir': './outputs/exp_t5_08020735',\n",
      "              'overwrite_output_dir': False,\n",
      "              'per_device_eval_batch_size': 8,\n",
      "              'per_device_train_batch_size': 8,\n",
      "              'predict_with_generate': True,\n",
      "              'remove_unused_columns': True,\n",
      "              'report_to': 'none',\n",
      "              'save_steps': 1,\n",
      "              'save_total_limit': 1,\n",
      "              'seed': 42,\n",
      "              'torch_empty_cache_steps': 1,\n",
      "              'warmup_steps': 10,\n",
      "              'weight_decay': 0.001},\n",
      " 'wandb': {'entity': 'skiersong',\n",
      "           'name': 'a_base_08020735',\n",
      "           'notes': 'AutoModel baseline',\n",
      "           'project': 'nlp-5-upgrade'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "config_path = os.path.join(\n",
    "    project_dir,'src','configs',\n",
    "    f\"config_{concept}_{current_time}.yaml\" # config 파일 이름을 설정\n",
    ")\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcd1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
