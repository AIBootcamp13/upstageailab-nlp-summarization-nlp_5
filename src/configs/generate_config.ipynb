{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642f7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer_name = \"digit82/kobart-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28bf67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS : <s> EOS : </s> Special_tokens : {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"BOS :\", tokenizer.bos_token,\n",
    "    \"EOS :\", tokenizer.eos_token,\n",
    "    \"Special_tokens :\", tokenizer.special_tokens_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 200,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', \n",
    "        '#DateOfBirth#','#PassportNumber#','#SSN#','#CardNumber#','#CarNumber#','#Email#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": 42,\n",
    "        \"output_dir\":\"baseline_test1\",\n",
    "        \"overwrite_output_dir\": False,\n",
    "\n",
    "        \"save_total_limit\": 1,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"save_steps\": 400,\n",
    "\n",
    "        \"logging_steps\": 100,\n",
    "\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"per_device_train_batch_size\": 64,\n",
    "        \"remove_unused_columns\": True,\n",
    "        \"fp16\": True,\n",
    "        \"dataloader_drop_last\": False,\n",
    "        \"group_by_length\": True,\n",
    "        \n",
    "        \"gradient_checkpointing\": True,\n",
    "        \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"torch_empty_cache_steps\": 10,\n",
    "        \"dataloader_num_workers\": 8,\n",
    "\n",
    "        \"per_device_eval_batch_size\": 48,\n",
    "        \"eval_strategy\": 'steps',\n",
    "        \"eval_steps\": 400,\n",
    "        \n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 200,\n",
    "        \n",
    "        # Callbacks\n",
    "        \"early_stopping_patience\": 1,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "\n",
    "        # Optimizer\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"warmup_steps\": 10,\n",
    "        \"weight_decay\": 0.01,\n",
    "\n",
    "        \"report_to\": \"all\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"skiersong\", # 팀 실험 시 organization 이름\n",
    "        \"project\": \"nlp-5\",\n",
    "        \"name\": \"baseline_test1_07250200\", # 개별 실험 이름\n",
    "        # \"group\": \"\", # 유사한 실험들은 같은 그룹으로 설정\n",
    "        # \"notes\": \"\", # 실험에 대한 추가 설명\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model-ckt-path\", # 파인튜닝이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 200,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616c2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '../data/',\n",
      "             'model_name': 'digit82/kobart-summarization',\n",
      "             'output_dir': './'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': 'model-ckt-path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 200,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 200,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#Email#']},\n",
      " 'training': {'dataloader_drop_last': False,\n",
      "              'dataloader_num_workers': 8,\n",
      "              'early_stopping_patience': 1,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'eval_steps': 400,\n",
      "              'eval_strategy': 'steps',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 200,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'gradient_checkpointing': True,\n",
      "              'gradient_checkpointing_kwargs': {'use_reentrant': False},\n",
      "              'group_by_length': True,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_steps': 100,\n",
      "              'num_train_epochs': 20,\n",
      "              'output_dir': 'baseline_test1',\n",
      "              'overwrite_output_dir': False,\n",
      "              'per_device_eval_batch_size': 48,\n",
      "              'per_device_train_batch_size': 64,\n",
      "              'predict_with_generate': True,\n",
      "              'remove_unused_columns': True,\n",
      "              'report_to': 'all',\n",
      "              'save_steps': 400,\n",
      "              'save_total_limit': 1,\n",
      "              'seed': 42,\n",
      "              'torch_empty_cache_steps': 10,\n",
      "              'warmup_steps': 10,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'skiersong',\n",
      "           'name': 'baseline_test1_07250200',\n",
      "           'project': 'nlp-5'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "project_dir = \"/mnt/c/SKH/ai_lab_13/projects/nlp-text-summarization/song\"\n",
    "config_path = os.path.join(\n",
    "    project_dir,'src','configs',\n",
    "    \"config_base.yaml\" # config 파일 이름을 설정\n",
    ")\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27711c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
