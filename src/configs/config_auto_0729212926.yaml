general:
  data_path: ./data/
  model_name: csebuetnlp/mT5_multilingual_XLSum
  output_dir: ./outputs/exp_auto_0729212926
inference:
  batch_size: 16
  ckt_dir: ./outputs/exp_auto_0729212926/best
  early_stopping: true
  generate_max_length: 160
  no_repeat_ngram_size: 2
  num_beams: 4
  remove_tokens:
  - <usr>
  - None
  - </s>
  - <pad>
  result_path: ./outputs/exp_auto_0729212926/submission_0729212926.csv
tokenizer:
  bos_token: None
  decoder_max_len: 160
  encoder_max_len: 1300
  eos_token: </s>
  special_tokens:
  - '#Person1#'
  - '#Person2#'
  - '#Person3#'
  - '#Person4#'
  - '#PhoneNumber#'
  - '#Address#'
  - '#DateOfBirth#'
  - '#PassportNumber#'
  - '#SSN#'
  - '#CardNumber#'
  - '#CarNumber#'
  - '#Email#'
training:
  bf16: true
  dataloader_drop_last: false
  dataloader_num_workers: 8
  early_stopping_patience: 3
  early_stopping_threshold: 0.001
  eval_steps: 400
  evaluation_strategy: steps
  fp16: false
  generation_max_length: 160
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  group_by_length: true
  learning_rate: 1.0e-05
  load_best_model_at_end: true
  logging_dir: ./outputs/exp_auto_0729212926
  logging_steps: 400
  num_train_epochs: 35
  output_dir: ./outputs/exp_auto_0729212926
  overwrite_output_dir: false
  per_device_eval_batch_size: 16
  per_device_train_batch_size: 16
  predict_with_generate: true
  remove_unused_columns: true
  report_to: none
  save_steps: 400
  save_total_limit: 1
  seed: 42
  torch_empty_cache_steps: 2
  warmup_steps: 10
  weight_decay: 0.001
wandb:
  entity: skiersong
  name: b_automodel_0729212926
  notes: 'b AutoModel '
  project: nlp-5
