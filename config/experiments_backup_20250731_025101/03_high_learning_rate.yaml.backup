# 고성능 학습률 실험
experiment_name: high_learning_rate
description: "높은 학습률로 빠른 수렴 실험"

general:
  model_name: digit82/kobart-summarization
  data_path: ../data/
  name: high_lr_experiment

tokenizer:
  bos_token: <s>
  eos_token: </s>
  encoder_max_len: 512
  decoder_max_len: 100

training:
  do_eval: true
  do_train: true
  evaluation_strategy: epoch
  num_train_epochs: 3  # 높은 학습률이므로 epoch 줄임
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  learning_rate: 5.0e-05  # 5배 높은 학습률
  fp16: true
  warmup_ratio: 0.2      # 웜업 비율 증가
  logging_steps: 50
  save_strategy: epoch
  save_total_limit: 2
  load_best_model_at_end: true
  early_stopping_patience: 2

wandb:
  entity: lyjune37-juneictlab
  project: nlp-5
  name: high_lr_experiment_lyj
  tags: [high_lr, fast_convergence, lyj]
