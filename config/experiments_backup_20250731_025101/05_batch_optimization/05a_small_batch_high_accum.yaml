experiment_name: batch_optimization_small_high_accum
description: Small batch size with high gradient accumulation (effective batch=64)

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 학습 구성 - 작은 배치, 높은 accumulation
training:
  num_train_epochs: 5  # 빠른 실험
  learning_rate: 1.0e-05
  
  # 배치 설정: 작은 배치 크기 + 높은 accumulation
  per_device_train_batch_size: 8    # 작은 배치 크기 (메모리 효율적)
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 8     # 높은 accumulation (효과적인 배치 크기 = 64)
  
  # 메모리 최적화
  gradient_checkpointing: true       # 메모리 절약
  fp16: true                        # Mixed precision
  optim: "adamw_8bit"              # 8-bit optimizer (더 많은 메모리 절약)
  
  # 표준 설정
  warmup_steps: 100
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: epoch
  save_strategy: epoch
  save_total_limit: 1
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  
  # 조기 종료
  early_stopping_patience: 2
  early_stopping_threshold: 0.001
  
  # 데이터로더 설정
  dataloader_num_workers: 2  # 작은 배치에는 적은 워커
  dataloader_drop_last: false
  group_by_length: true
  predict_with_generate: true
  remove_unused_columns: true
  
  # 메모리 관리
  torch_empty_cache_steps: 50  # 자주 캐시 비우기

# 생성 구성
generation:
  max_length: 200
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  length_penalty: 1.0

# 추론 구성
inference:
  batch_size: 8  # 추론도 작은 배치
  generate_max_length: 200
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# WandB 구성
wandb:
  name: "05a_batch_small_high_accum"
  notes: "Batch optimization: small batch (8) + high accumulation (8) = effective 64"
  tags: ["batch_optimization", "small_batch", "high_accumulation", "memory_efficient", "kobart"]
  
# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"

# 성능 모니터링
monitoring:
  log_memory_usage: true      # 메모리 사용량 로깅
  log_training_speed: true    # 학습 속도 로깅
  log_gpu_stats: true        # GPU 통계 로깅
