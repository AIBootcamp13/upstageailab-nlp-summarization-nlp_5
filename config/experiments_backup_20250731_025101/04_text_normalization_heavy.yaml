experiment_name: text_normalization_heavy
description: Heavy text normalization - aggressive noise reduction

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 텍스트 정규화 구성 - Heavy 레벨
text_normalization:
  enabled: true
  normalize_level: "heavy"  # 적극적인 정규화
  
  # 정규화 옵션 - Heavy는 모든 옵션 활성화
  normalize_abbreviations: true   # 약어 정규화
  normalize_emoticons: true       # 이모티콘 정규화
  remove_repeated_chars: true     # 반복 문자 제거
  clean_punctuation: true         # 문장부호 정리
  remove_fillers: true           # 간투사 제거
  aggressive_cleaning: true       # 적극적인 정리
  
  # 로깅 설정
  log_samples: true
  log_sample_count: 20  # 더 많은 샘플 로깅
  save_normalized_data: true
  normalized_data_path: "outputs/normalized_data_heavy"
  save_statistics: true  # 정규화 통계 저장

# 학습 구성 - 정규화로 인한 데이터 변화를 고려
training:
  num_train_epochs: 20
  learning_rate: 1.5e-05  # 약간 높은 학습률 (정규화된 데이터에 빠른 적응)
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  gradient_checkpointing: true
  fp16: true
  warmup_ratio: 0.1  # 비율 기반 웜업
  weight_decay: 0.01
  seed: 42
  
  # 평가 설정
  evaluation_strategy: steps
  eval_steps: 400
  save_steps: 400
  save_total_limit: 1
  logging_steps: 100
  
  # 조기 종료 - 더 관대하게
  early_stopping_patience: 5  # 정규화 효과를 충분히 보기 위해
  early_stopping_threshold: 0.001
  load_best_model_at_end: true

# 생성 구성 - 정규화된 데이터에 맞춰 조정
generation:
  max_length: 180  # 정규화로 짧아진 텍스트 고려
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  length_penalty: 1.0

# 추론 구성
inference:
  batch_size: 16
  generate_max_length: 180
  apply_normalization: true
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# WandB 구성
wandb:
  name: "04_text_normalization_heavy"
  notes: "Aggressive text normalization for maximum noise reduction"
  tags: ["normalization", "preprocessing", "heavy", "aggressive", "noise_reduction", "kobart"]
  
# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"

# Generation settings
generation:
  max_length: 256
  min_length: 5
  num_beams: 4
  no_repeat_ngram_size: 2
\ntraining:\n  eval_strategy: no
