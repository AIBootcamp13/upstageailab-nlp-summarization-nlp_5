experiment_name: high_learning_rate
description: Experiment with higher learning rate
model:
  name: digit82/kobart-summarization
training:
  learning_rate: 5.0e-05
  per_device_train_batch_size: 8
  num_train_epochs: 5
wandb:
  name: 02_high_lr_experiment

# Generation settings
generation:
  max_length: 256
  min_length: 5
  num_beams: 4
  no_repeat_ngram_size: 2
\ntraining:\n  eval_strategy: no
