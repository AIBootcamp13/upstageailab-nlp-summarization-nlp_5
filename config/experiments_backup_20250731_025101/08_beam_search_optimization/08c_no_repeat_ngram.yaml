experiment_name: beam_search_no_repeat_ngram
description: 반복 방지 n-gram 크기 최적화 - no_repeat_ngram_size 조정

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 학습 구성 (빠른 테스트를 위해 짧게)
training:
  num_train_epochs: 3
  learning_rate: 2.0e-05
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  warmup_steps: 300
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: epoch
  save_strategy: epoch
  save_total_limit: 1
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  fp16: true
  gradient_checkpointing: true
  predict_with_generate: true

# 생성 구성 - 반복 방지 실험
generation:
  # 고정 파라미터
  num_beams: 4
  max_length: 200
  min_length: 30
  length_penalty: 1.2  # 이전 실험의 최적값
  early_stopping: true
  
  # no_repeat_ngram_size별 실험
  experiments:
    - name: "no_repeat_0"
      no_repeat_ngram_size: 0  # 반복 허용 (베이스라인)
      
    - name: "no_repeat_2"
      no_repeat_ngram_size: 2  # 2-gram 반복 방지
      
    - name: "no_repeat_3"
      no_repeat_ngram_size: 3  # 3-gram 반복 방지
      
    - name: "no_repeat_4"
      no_repeat_ngram_size: 4  # 4-gram 반복 방지
      
    - name: "no_repeat_5"
      no_repeat_ngram_size: 5  # 5-gram 반복 방지

# 추론 구성
inference:
  batch_size: 16
  measure_time: true
  
  # 반복 관련 메트릭
  metrics:
    - rouge
    - repetition_metrics:
        - ngram_repetition_rate  # n-gram 반복률
        - self_bleu  # 자기 유사도
        - distinct_ngrams  # 고유 n-gram 비율
        - lexical_diversity  # 어휘 다양성
    - fluency_score  # 유창성 점수
    - coherence_score  # 일관성 점수
    
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# 반복 분석 설정
repetition_analysis:
  enabled: true
  
  # 분석할 n-gram 크기
  ngram_sizes: [1, 2, 3, 4, 5]
  
  # 반복 패턴 분석
  analyze_patterns:
    - phrase_repetition  # 구문 반복
    - word_repetition  # 단어 반복
    - semantic_repetition  # 의미적 반복
    - structural_repetition  # 구조적 반복
  
  # 반복 임계값
  thresholds:
    acceptable_2gram_repeat: 0.1  # 10% 이하
    acceptable_3gram_repeat: 0.05  # 5% 이하
    acceptable_4gram_repeat: 0.02  # 2% 이하
  
  # 시각화
  plots:
    - ngram_size_vs_repetition_rate
    - ngram_size_vs_rouge
    - repetition_heatmap
    - diversity_radar_chart

# 특수 케이스 처리
special_cases:
  # 반복이 필요한 경우 예외 처리
  allowed_repetitions:
    - special_tokens  # 특수 토큰은 반복 허용
    - numbers  # 숫자는 반복 가능
    - proper_nouns  # 고유명사 반복 허용
  
  # 문맥상 반복이 자연스러운 경우
  contextual_exceptions:
    - emphasis  # 강조를 위한 반복
    - listing  # 나열 시 반복

# WandB 구성
wandb:
  name: "08c_no_repeat_ngram_optimization"
  notes: "반복 방지 n-gram 크기 최적화 - 0에서 5까지 실험"
  tags: ["beam_search", "no_repeat", "repetition", "optimization", "kobart"]
  
  # 추가 로깅
  log_repetition_examples: true
  log_diversity_metrics: true

# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"
  
  # 반복이 많은 샘플 추가 분석
  identify_repetitive_samples: true
  repetition_threshold: 0.3  # 30% 이상 반복

# 모니터링 설정
monitoring:
  log_repetition_stats: true
  log_diversity_scores: true
  
  # 실시간 반복 탐지
  detect_repetition_realtime: true
  alert_on_high_repetition: true
