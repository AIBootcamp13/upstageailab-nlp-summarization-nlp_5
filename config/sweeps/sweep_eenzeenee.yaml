# WandB Sweep 설정 - eenzeenee 모델 하이퍼파라미터 튜닝
program: code/trainer.py
method: bayes  # 베이지안 최적화
entity: lyjune37-juneictlab  # .env에서 로드되지만 명시적 지정
project: nlp-5
metric:
  goal: maximize
  name: eval_rouge_combined_f1  # 통합 ROUGE F1 스코어 사용
parameters:
  # 학습률 최적화
  learning_rate:
    distribution: log_uniform_values
    min: 1e-5
    max: 1e-4
  
  # 배치 크기 최적화
  per_device_train_batch_size:
    values: [4, 8, 16]  # T5 base 크기에 적합
  
  # 그래디언트 누적
  gradient_accumulation_steps:
    values: [1, 2, 4]
  
  # 워밍업 비율
  warmup_ratio:
    values: [0.05, 0.1, 0.2]
  
  # 가중치 감쇠
  weight_decay:
    distribution: uniform
    min: 0.0
    max: 0.1
  
  # 학습 에포크
  num_train_epochs:
    values: [5, 10, 15]
  
  # 생성 파라미터
  generation_num_beams:
    values: [3, 4, 5]
  
  generation_max_length:
    values: [64, 96, 128]  # 한국어 요약 최적 길이
  
  # 학습률 스케줄러
  lr_scheduler_type:
    values: ["linear", "cosine", "cosine_with_restarts"]
  
  # 고정 파라미터
  config:
    value: config/experiments/02_eenzeenee_t5.yaml
  
  sweep:
    value: true  # Sweep 모드 활성화

# 조기 종료 설정 (Hyperband)
early_terminate:
  type: hyperband
  s: 2  # 최대 bracket 수
  eta: 3  # 각 bracket에서 살아남는 실행의 비율
  max_iter: 20  # 최대 에포크
