experiment_name: combination_phase1_aug_plus_lr
description: 1차 조합 실험 - 데이터 증강 + 최적 학습률 스케줄링

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 학습 구성
training:
  num_train_epochs: 20
  learning_rate: 3.0e-05  # 더 높은 초기 학습률
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4  # 효과적인 배치 크기 = 64
  
  # Cosine Annealing 스케줄러 (이전 실험에서 가장 효과적)
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.1  # 전체 스텝의 10%를 warmup
  
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: epoch
  save_strategy: epoch
  save_total_limit: 3
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  fp16: true
  gradient_checkpointing: true
  
  # 조기 종료
  early_stopping_patience: 3
  early_stopping_threshold: 0.001
  
  # 데이터로더 설정
  dataloader_num_workers: 4
  dataloader_drop_last: false
  group_by_length: true
  predict_with_generate: true
  remove_unused_columns: true

# 데이터 증강 설정
data_augmentation:
  enabled: true
  augmenters:
    - type: "SynonymReplacement"
      params:
        replace_ratio: 0.15
        preserve_special_tokens: true
        preserve_speakers: true
    - type: "SentenceReorder"
      params:
        reorder_ratio: 0.2
        preserve_speaker_order: true
        preserve_context_window: 3
  augmentation_ratio: 0.3  # 원본 데이터의 30% 증강

# 생성 구성
generation:
  max_length: 200
  min_length: 30
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  length_penalty: 1.0
  temperature: 1.0
  do_sample: false

# 추론 구성
inference:
  batch_size: 16
  generate_max_length: 200
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# WandB 구성
wandb:
  name: "06b_combination_aug_lr"
  notes: "조합 실험 1차: 데이터 증강 + Cosine Annealing LR 스케줄링"
  tags: ["combination", "phase1", "augmentation", "lr_scheduling", "kobart"]
  
# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"

# 모니터링 설정
monitoring:
  log_memory_usage: true
  log_training_speed: true
  log_augmentation_stats: true
  log_lr_curve: true  # 학습률 변화 로깅
