experiment_name: beam_search_length_penalty
description: 빔 서치 길이 패널티 최적화 - length_penalty 파라미터 조정

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 학습 구성 (빠른 테스트를 위해 짧게)
training:
  num_train_epochs: 3
  learning_rate: 2.0e-05
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  warmup_steps: 300
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: epoch
  save_strategy: epoch
  save_total_limit: 1
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  fp16: true
  gradient_checkpointing: true
  predict_with_generate: true

# 생성 구성 - 길이 패널티 실험
generation:
  # 고정 파라미터
  num_beams: 4  # 최적값 사용
  max_length: 200
  min_length: 30
  no_repeat_ngram_size: 2
  early_stopping: true
  
  # 길이 패널티별 실험
  experiments:
    - name: "length_penalty_0.5"
      length_penalty: 0.5  # 짧은 문장 선호
      
    - name: "length_penalty_0.8"
      length_penalty: 0.8
      
    - name: "length_penalty_1.0"
      length_penalty: 1.0  # 기본값
      
    - name: "length_penalty_1.2"
      length_penalty: 1.2
      
    - name: "length_penalty_1.5"
      length_penalty: 1.5
      
    - name: "length_penalty_2.0"
      length_penalty: 2.0  # 긴 문장 선호

# 추론 구성
inference:
  batch_size: 16
  measure_time: true
  
  # 길이 관련 메트릭 추가
  metrics:
    - rouge
    - length_accuracy  # 목표 길이 대비 정확도
    - compression_ratio  # 압축 비율
    - content_coverage  # 내용 포함도
    - readability  # 가독성
    
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# 길이 분석 설정
length_analysis:
  enabled: true
  
  # 목표 길이 설정
  target_length_ratio: 0.3  # 원본 대비 30%
  acceptable_range: [0.25, 0.35]  # 허용 범위
  
  # 분석 메트릭
  analyze:
    - length_distribution  # 길이 분포
    - length_vs_quality  # 길이와 품질 관계
    - penalty_effectiveness  # 패널티 효과성
    - content_preservation  # 핵심 내용 보존율
  
  # 시각화
  plots:
    - length_penalty_vs_avg_length
    - length_penalty_vs_rouge
    - length_distribution_boxplot
    - optimal_penalty_curve

# WandB 구성
wandb:
  name: "08b_length_penalty_optimization"
  notes: "길이 패널티 최적화 - 0.5에서 2.0까지 6단계 실험"
  tags: ["beam_search", "length_penalty", "optimization", "kobart"]
  
  # 추가 로깅
  log_length_statistics: true
  log_sample_comparisons: true

# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"
  
  # 길이 분석을 위한 추가 처리
  compute_source_lengths: true
  length_buckets: [100, 200, 300, 400, 500]  # 원본 길이별 버킷

# 모니터링 설정
monitoring:
  log_length_metrics: true
  log_compression_stats: true
  
  # 길이별 성능 추적
  track_by_length_bucket: true
  length_bucket_metrics:
    - rouge_by_bucket
    - compression_by_bucket
