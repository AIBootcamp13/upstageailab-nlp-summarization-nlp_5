# mT5 XL-Sum RTX 3090 극한 최적화 실험 2단계 (한국어 도메인 적응)
experiment_name: mt5_xlsum_extreme_stage2_korean_adapted
description: "mT5 XL-Sum RTX 3090 + Unsloth 극한 최적화 2단계 - 배치 10 + 시퀀스 1280 + 한국어 도메인 적응"

general:
  model_name: csebuetnlp/mT5_multilingual_XLSum
  data_path: data/
  train_path: data/train.csv
  val_path: data/dev.csv
  model_type: seq2seq
  name: mt5_xlsum_extreme_stage2_korean_adapted

model:
  architecture: mt5
  checkpoint: csebuetnlp/mT5_multilingual_XLSum

# 🔥 극한 최적화 한국어 대화 요약 도메인 적응 prefix
input_prefix: "dialogue summarization in korean: "

tokenizer:
  bos_token: <pad>
  eos_token: </s>
  encoder_max_len: 1280              # 2단계: 768→1280 극한 확장
  decoder_max_len: 230               # 2단계: 150→230 확장
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#PassportNumber#'
    - '#DateOfBirth#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'
    - '<대화시작>'
    - '<대화종료>'
    - '<중요>'
    - '<결론>'
    - '<summary>'
    - '</summary>'
    - '<dialogue>'
    - '</dialogue>'

# 🔥 RTX 3090 + Unsloth 극한 최적화 2단계 (한국어 도메인 적응)
training:
  do_eval: true
  do_train: true
  evaluation_strategy: steps
  eval_steps: 100                     # 더 자주 평가
  
  # 🔥 2단계 극한 최적화 배치 설정
  per_device_train_batch_size: 10     # 5→10 2배 증가
  per_device_eval_batch_size: 20      # 10→20 2배 증가
  gradient_accumulation_steps: 5      # 유효 배치 50 유지
  
  # ⚡ 2단계 도메인 적응 특화 학습 파라미터
  num_train_epochs: 7                 # 최적화로 더 긴 도메인 적응
  learning_rate: 1.0e-04              # 2단계 더 높은 학습률
  lr_scheduler_type: cosine_with_restarts
  warmup_ratio: 0.02                  # 짧은 웜업
  weight_decay: 0.0001                # 세밀한 정규화
  
  # 🔥 RTX 3090 + CUDA 12.2 + Unsloth 극한 최적화
  fp16: false                         # bf16 사용으로 변경
  bf16: true                          # RTX 3090 + CUDA 12.2 최적
  tf32: true                          # Ampere 아키텍처 최적화
  gradient_checkpointing: false       # Unsloth 자체 최적화
  dataloader_num_workers: 34          # 48코어의 70% 활용
  dataloader_pin_memory: true         # 251GB RAM 활용
  dataloader_persistent_workers: true # 워커 재사용
  group_by_length: true
  remove_unused_columns: false        # 전체 정보 활용
  
  # 🔥 Unsloth 특화 옵티마이저 설정
  optim: adamw_8bit                   # Unsloth 호환 옵티마이저
  adam_beta1: 0.9
  adam_beta2: 0.95                    # Unsloth 추천값
  max_grad_norm: 0.3                  # Unsloth와 함께 낮은 값
  
  # 📊 세밀한 모니터링
  logging_steps: 25
  save_strategy: steps
  save_steps: 150
  save_total_limit: 10                # 더 많은 체크포인트 저장
  load_best_model_at_end: true
  early_stopping_patience: 10         # 충분한 도메인 적응 시간
  
  # 🏆 2단계 한국어 도메인 적응 특화 생성
  predict_with_generate: true
  generation_num_beams: 14            # 8→14 속도 향상
  generation_max_length: 230          # 150→230 증가
  generation_min_length: 20           # 15→20 최소 길이 증가
  generation_length_penalty: 0.75     # 길이 패널티 조정
  generation_no_repeat_ngram_size: 3  # 반복 방지 유지
  generation_do_sample: false         # 결정론적 생성
  generation_early_stopping: true     # 조기 중단 활성화
  
  report_to: wandb
  seed: 42

# 🔥 RTX 3090 + Unsloth 극한 최적화 2단계 QLoRA
qlora:
  use_unsloth: true                   # Unsloth 활성화
  use_qlora: true
  lora_rank: 192                      # 64→192 3배 증가
  lora_alpha: 384                     # 128→384 3배 증가
  lora_dropout: 0.01                  # 0.03→0.01 드롭아웃 감소
  target_modules: ["q", "k", "v", "o", "wi", "wo", "lm_head", "embed_tokens"]  # 모듈 확장
  load_in_4bit: true
  bnb_4bit_compute_dtype: "bfloat16"   # RTX 3090 + CUDA 12.2 최적
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true

wandb:
  entity: lyjune37-juneictlab
  project: nlp-5
  name: mt5_xlsum_extreme_stage2_korean_adapted
  tags: [mT5, XL-Sum, RTX3090, extreme_stage2, korean_adapted, Unsloth, batch10, seq1280]
  notes: "mT5 XL-Sum RTX 3090 + Unsloth 극한 최적화 2단계 - 배치 10, 시퀀스 1280, LoRA 192, 한국어 도메인 적응"

# 🏆 2단계 극한 최적화 생성 설정
generation:
  max_length: 230                     # 더 긴 요약 허용
  min_length: 20                      # 최소 길이 증가
  num_beams: 14                       # 다양한 후보 탐색
  length_penalty: 0.75                # 길이 패널티
  no_repeat_ngram_size: 3             # 반복 방지
  early_stopping: true                # 조기 중단
  do_sample: false                    # 결정론적 생성
