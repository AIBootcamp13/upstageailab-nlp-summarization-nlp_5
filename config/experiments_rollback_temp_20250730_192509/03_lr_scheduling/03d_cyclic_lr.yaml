experiment_name: lr_scheduling_cyclic
description: Cyclic learning rate with triangular policy

# Model configuration
model:
  name: digit82/kobart-summarization
  architecture: kobart

# Tokenizer configuration  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# Training configuration with cyclic LR
training:
  num_train_epochs: 5  # Quick experiment
  learning_rate: 3.0e-05  # Max LR for cycling
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  gradient_checkpointing: true
  fp16: true
  
  # Cyclic LR settings using cosine with restarts
  lr_scheduler_type: "cosine_with_restarts"  # Cosine with restarts for cyclic behavior
  warmup_ratio: 0.05  # Short warmup for each cycle
  lr_scheduler_kwargs:
    num_cycles: 2  # Number of cosine cycles
  
  # Alternative: OneCycleLR-like behavior with linear
  # lr_scheduler_type: "linear"
  # warmup_steps: 200  # Ramp up
  # lr_scheduler_kwargs:
  #   num_training_steps: 1000  # Then ramp down
  
  # Standard settings
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: steps  # More frequent evaluation for cyclic
  eval_steps: 200
  save_strategy: steps
  save_steps: 200
  save_total_limit: 3  # Keep more checkpoints
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  
  # Early stopping
  early_stopping_patience: 4  # More patience for cyclic
  early_stopping_threshold: 0.001
  
  # Other settings
  dataloader_num_workers: 4
  dataloader_drop_last: false
  group_by_length: true
  predict_with_generate: true
  remove_unused_columns: true

# Generation configuration
generation:
  max_length: 200
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  length_penalty: 1.0

# Inference configuration
inference:
  batch_size: 16
  generate_max_length: 200
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# WandB configuration
wandb:
  name: "03d_lr_cyclic"
  notes: "LR scheduling with cyclic/restart policy using cosine with restarts"
  tags: ["lr_scheduling", "cyclic_lr", "cosine_restarts", "optimization", "kobart"]
  
# Data configuration
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"

# Logging configuration
logging:
  log_lr: true
  log_lr_every_step: true  # Log every step to see cycles
