experiment_name: longer_training
description: Experiment with more epochs
model:
  name: digit82/kobart-summarization
training:
  learning_rate: 1.0e-05
  per_device_train_batch_size: 8
  num_train_epochs: 10
wandb:
  name: 04_longer_training_experiment

# Generation settings
generation:
  max_length: 256
  min_length: 5
  num_beams: 4
  no_repeat_ngram_size: 2
\ntraining:\n  eval_strategy: no
