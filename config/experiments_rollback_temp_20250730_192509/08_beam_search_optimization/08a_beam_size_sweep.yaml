experiment_name: beam_search_size_optimization
description: 빔 서치 크기 최적화 실험 - 다양한 num_beams 값 테스트

# 모델 구성
model:
  name: digit82/kobart-summarization
  architecture: kobart

# 토크나이저 구성  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# 학습 구성 (빠른 테스트를 위해 짧게)
training:
  num_train_epochs: 3  # 추론 성능 테스트가 주목적
  learning_rate: 2.0e-05
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  warmup_steps: 300
  weight_decay: 0.01
  seed: 42
  evaluation_strategy: epoch
  save_strategy: epoch
  save_total_limit: 1
  logging_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: "eval_rouge_combined_f1"
  greater_is_better: true
  fp16: true
  gradient_checkpointing: true
  predict_with_generate: true

# 생성 구성 - 빔 크기 실험
generation:
  # 빔 크기별 실험 설정
  experiments:
    - name: "beam_2"
      num_beams: 2
      max_length: 200
      min_length: 30
      no_repeat_ngram_size: 2
      early_stopping: true
      length_penalty: 1.0
      
    - name: "beam_4"
      num_beams: 4
      max_length: 200
      min_length: 30
      no_repeat_ngram_size: 2
      early_stopping: true
      length_penalty: 1.0
      
    - name: "beam_6"
      num_beams: 6
      max_length: 200
      min_length: 30
      no_repeat_ngram_size: 2
      early_stopping: true
      length_penalty: 1.0
      
    - name: "beam_8"
      num_beams: 8
      max_length: 200
      min_length: 30
      no_repeat_ngram_size: 2
      early_stopping: true
      length_penalty: 1.0

# 추론 구성
inference:
  batch_size: 8  # 빔 크기가 클수록 메모리 사용 증가
  measure_time: true  # 추론 시간 측정
  measure_memory: true  # 메모리 사용량 측정
  
  # 평가 메트릭
  metrics:
    - rouge
    - bertscore  # 의미적 유사도
    - repetition_rate  # 반복 비율
    - length_ratio  # 길이 비율
    - inference_time  # 추론 시간
    
  remove_tokens:
    - '<usr>'
    - '<s>'
    - '</s>'
    - '<pad>'

# 빔 서치 분석 설정
beam_search_analysis:
  enabled: true
  
  # 분석할 메트릭
  analyze_metrics:
    - quality_vs_speed  # 품질 대비 속도
    - repetition_analysis  # 반복 패턴 분석
    - length_distribution  # 생성 길이 분포
    - diversity_score  # 생성 다양성
  
  # 샘플링
  sample_outputs: true
  num_samples: 50  # 각 설정당 샘플 수
  
  # 시각화
  create_plots: true
  plot_types:
    - beam_size_vs_rouge
    - beam_size_vs_time
    - quality_speed_tradeoff

# WandB 구성
wandb:
  name: "08a_beam_size_optimization"
  notes: "빔 서치 크기 최적화 - num_beams 2,4,6,8 비교"
  tags: ["beam_search", "inference", "optimization", "kobart"]
  
  # 추가 로깅
  log_generation_samples: true
  log_beam_scores: true
  
# 데이터 구성
data:
  train_file: "train.csv"
  dev_file: "dev.csv"
  test_file: "test.csv"
  
  # 빠른 실험을 위한 서브셋
  use_subset: true
  subset_size: 1000  # 테스트용 작은 데이터셋

# 모니터링 설정
monitoring:
  log_memory_usage: true
  log_inference_speed: true
  log_beam_statistics: true
  
  # 빔별 통계
  track_beam_scores: true
  track_sequence_probabilities: true
