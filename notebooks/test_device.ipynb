{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디바이스 자동 감지 테스트\n",
    "\n",
    "이 노트북은 MPS/CUDA 자동 감지 시스템을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 상위 디렉토리의 code를 import 경로에 추가\n",
    "sys.path.append(str(Path.cwd().parent / 'code'))\n",
    "\n",
    "from utils.device_utils import (\n",
    "    get_system_info, \n",
    "    detect_cuda_devices, \n",
    "    detect_mps_device,\n",
    "    get_optimal_device, \n",
    "    setup_device_config,\n",
    "    print_device_summary\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 시스템 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 정보 수집\n",
    "sys_info = get_system_info()\n",
    "\n",
    "print(\"=== 시스템 정보 ===\")\n",
    "for key, value in sys_info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 디바이스 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA 디바이스 감지\n",
    "print(\"=== CUDA 디바이스 ===\")\n",
    "cuda_devices = detect_cuda_devices()\n",
    "if cuda_devices:\n",
    "    for idx, device in cuda_devices.items():\n",
    "        print(f\"GPU {idx}: {device}\")\n",
    "        print(f\"  - 메모리: {device.memory_gb:.2f} GB\")\n",
    "        print(f\"  - Compute Capability: {device.compute_capability}\")\n",
    "else:\n",
    "    print(\"CUDA 디바이스를 찾을 수 없습니다.\")\n",
    "\n",
    "# MPS 디바이스 감지\n",
    "print(\"\\n=== MPS 디바이스 ===\")\n",
    "mps_device = detect_mps_device()\n",
    "if mps_device:\n",
    "    print(f\"MPS: {mps_device}\")\n",
    "else:\n",
    "    print(\"MPS 디바이스를 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 최적 디바이스 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 디바이스 자동 선택\n",
    "device, device_info = get_optimal_device()\n",
    "\n",
    "print(f\"선택된 디바이스: {device}\")\n",
    "print(f\"디바이스 정보: {device_info}\")\n",
    "\n",
    "# PyTorch 텐서 테스트\n",
    "test_tensor = torch.randn(10, 10).to(device)\n",
    "print(f\"\\n테스트 텐서 디바이스: {test_tensor.device}\")\n",
    "print(f\"텐서 크기: {test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 디바이스별 최적화 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 크기별 최적화 설정 확인\n",
    "model_sizes = ['small', 'base', 'large']\n",
    "\n",
    "print(f\"디바이스: {device_info}\\n\")\n",
    "\n",
    "for size in model_sizes:\n",
    "    config = setup_device_config(device_info, size)\n",
    "    print(f\"=== {size.upper()} 모델 설정 ===\")\n",
    "    print(f\"배치 크기: {config.batch_size}\")\n",
    "    print(f\"Mixed Precision: {config.mixed_precision}\")\n",
    "    print(f\"FP16: {config.fp16}\")\n",
    "    print(f\"Gradient Accumulation: {config.gradient_accumulation_steps}\")\n",
    "    print(f\"DataLoader Workers: {config.num_workers}\")\n",
    "    print(f\"Pin Memory: {config.pin_memory}\")\n",
    "    print(f\"Gradient Checkpointing: {config.gradient_checkpointing}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 환경변수 확인 (MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# MPS 관련 환경변수 확인\n",
    "if device_info.device_type == 'mps':\n",
    "    print(\"=== MPS 환경변수 ===\")\n",
    "    mps_env_vars = [\n",
    "        'PYTORCH_MPS_HIGH_WATERMARK_RATIO',\n",
    "        'PYTORCH_ENABLE_MPS_FALLBACK'\n",
    "    ]\n",
    "    \n",
    "    for var in mps_env_vars:\n",
    "        value = os.environ.get(var, 'Not set')\n",
    "        print(f\"{var}: {value}\")\n",
    "else:\n",
    "    print(\"MPS 디바이스가 아니므로 MPS 환경변수가 설정되지 않았습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 전체 디바이스 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 요약 정보 출력\n",
    "print_device_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trainer 통합 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 클래스에서 디바이스 설정 테스트\n",
    "from trainer import DialogueSummarizationTrainer\n",
    "from utils.config_manager import ConfigManager\n",
    "\n",
    "# 테스트용 설정\n",
    "test_config = {\n",
    "    'general': {\n",
    "        'device': 'auto',  # 자동 감지\n",
    "        'output_dir': 'test_output'\n",
    "    },\n",
    "    'model': {\n",
    "        'name': 'gogamza/kobart-summarization',\n",
    "        'size': 'base'\n",
    "    },\n",
    "    'training': {\n",
    "        # 빈 설정 - 자동으로 채워질 예정\n",
    "    }\n",
    "}\n",
    "\n",
    "# Trainer 초기화 (디바이스 설정만 테스트)\n",
    "trainer = DialogueSummarizationTrainer(\n",
    "    config=test_config,\n",
    "    experiment_name='device_test'\n",
    ")\n",
    "\n",
    "print(f\"\\nTrainer 디바이스: {trainer.device}\")\n",
    "print(f\"\\n자동 적용된 학습 설정:\")\n",
    "for key, value in trainer.config['training'].items():\n",
    "    if key in ['per_device_train_batch_size', 'mixed_precision', 'dataloader_num_workers', 'fp16']:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 성능 벤치마크 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 간단한 성능 테스트\n",
    "def benchmark_device(device, size=1000):\n",
    "    \"\"\"디바이스 성능 벤치마크\"\"\"\n",
    "    # 행렬 곱셈 테스트\n",
    "    a = torch.randn(size, size).to(device)\n",
    "    b = torch.randn(size, size).to(device)\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(10):\n",
    "        _ = torch.matmul(a, b)\n",
    "    \n",
    "    # 실제 측정\n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(100):\n",
    "        c = torch.matmul(a, b)\n",
    "    \n",
    "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
    "    end = time.time()\n",
    "    \n",
    "    return (end - start) / 100\n",
    "\n",
    "# 벤치마크 실행\n",
    "if device.type != 'cpu':  # GPU/MPS에서만 실행\n",
    "    print(\"=== 성능 벤치마크 ===\")\n",
    "    for size in [500, 1000, 2000]:\n",
    "        try:\n",
    "            time_taken = benchmark_device(device, size)\n",
    "            gflops = (2 * size**3) / (time_taken * 1e9)\n",
    "            print(f\"행렬 크기 {size}x{size}: {time_taken*1000:.2f}ms, {gflops:.2f} GFLOPS\")\n",
    "        except Exception as e:\n",
    "            print(f\"행렬 크기 {size}x{size}: 메모리 부족 또는 오류 - {e}\")\n",
    "else:\n",
    "    print(\"CPU에서는 벤치마크를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "MPS/CUDA 자동 감지 시스템이 성공적으로 구현되었습니다:\n",
    "\n",
    "1. **자동 디바이스 감지**: CUDA > MPS > CPU 우선순위로 최적 디바이스 선택\n",
    "2. **플랫폼별 최적화**: 각 디바이스에 맞는 배치 크기, mixed precision, worker 수 등 자동 설정\n",
    "3. **메모리 기반 조정**: GPU 메모리 크기에 따른 동적 설정 조정\n",
    "4. **환경변수 설정**: MPS 사용 시 필요한 환경변수 자동 설정\n",
    "5. **Trainer 통합**: DialogueSummarizationTrainer에 자동 통합되어 별도 설정 없이 사용 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}