# 베이스라인 재현 결과

## 개요
이 문서는 NLP 대화 요약 과제의 베이스라인 재현 결과를 포함합니다.

**목표 성능**: ROUGE-F1 47.12 (±2%)

## 실험 설정

### 모델
- **모델명**: digit82/kobart-summarization
- **아키텍처**: KoBART (Korean BART)
- **사전 훈련**: 예

### 학습 설정
- **학습률**: 1e-5
- **배치 크기**: 64 (디바이스당)
- **에포크**: 20
- **옵티마이저**: AdamW
- **가중치 감소**: 0.01
- **워밍업 단계**: 10
- **FP16**: 활성화

### 특수 토큰
- 화자 식별자: #Person1#, #Person2#, #Person3#
- PII 토큰: #PhoneNumber#, #Address#, #DateOfBirth#, #PassportNumber#, #SSN#, #CardNumber#, #CarNumber#, #Email#

### 데이터
- **학습 샘플**: 12,457개
- **검증 샘플**: 499개
- **테스트 샘플**: 250개

## 결과

### 성능 지표
| 지표 | 점수 | 목표 | 상태 |
|------|------|------|------|
| ROUGE-1 F1 | 미정 | ~0.47 | 대기 중 |
| ROUGE-2 F1 | 미정 | ~0.47 | 대기 중 |
| ROUGE-L F1 | 미정 | ~0.47 | 대기 중 |
| **통합 F1** | 미정 | 0.4712 | 대기 중 |

### 학습 통계
- **총 학습 시간**: 미정
- **평균 에포크 시간**: 미정
- **GPU 메모리 사용량**: 미정
- **최적 에포크**: 미정

### 학습 곡선
- 학습 손실: 미정
- 검증 손실: 미정
- 조기 중단 발생 에포크: 미정

## 관찰 사항

### 주요 발견사항
1. 모델 수렴 동작: 미정
2. 특수 토큰 처리 효과성: 미정
3. 그래디언트 체크포인팅을 통한 메모리 효율성: 미정

### 직면한 과제
- 미정

### 원본 베이스라인과의 비교
- 원본 보고: ROUGE-F1 47.12
- 우리의 재현: 미정
- 차이: 미정

## 파일 위치
- **설정 파일**: `config/experiments/00_baseline_reproduction.yaml`
- **모델 체크포인트**: 미정
- **학습 로그**: 미정
- **WandB 실행**: 미정

## 다음 단계
1. 재현 정확도 검증 (원본의 ±2% 이내)
2. 모든 후속 실험의 벤치마크로 사용
3. 향후 참조를 위한 차이점 문서화

---
*최종 업데이트: 2025-07-26*
*실험 ID: 00_baseline_reproduction*
