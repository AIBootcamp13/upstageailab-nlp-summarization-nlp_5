# ğŸ“š ì°¸ê³  ìë£Œ

NLP ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ì™¸ë¶€ ìë£Œ ë° ì¶”ê°€ í•™ìŠµ ë¦¬ì†ŒìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•œ ì„¹ì…˜ì…ë‹ˆë‹¤.

## ğŸ“‹ í¬í•¨ ë¬¸ì„œ

### ğŸ“– ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- **ë…¼ë¬¸ ë° ì—°êµ¬ìë£Œ** - ëŒ€í™” ìš”ì•½ ê´€ë ¨ ìµœì‹  ì—°êµ¬ ë…¼ë¬¸ ë° ë°ì´í„°ì…‹
- **ë¸”ë¡œê·¸ ë° íŠœí† ë¦¬ì–¼** - ì‹¤ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ê¸°ìˆ  ë¸”ë¡œê·¸ ë° í•™ìŠµ ìë£Œ
- **ê³µì‹ ë¬¸ì„œ** - ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë„êµ¬ì˜ ê³µì‹ ë¬¸ì„œ ë§í¬

### ğŸ› ï¸ ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
- **Transformers** - Hugging Face Transformers í™œìš© ê°€ì´ë“œ
- **PyTorch** - PyTorch ê´€ë ¨ ì°¸ê³  ìë£Œ
- **WandB** - ì‹¤í—˜ ì¶”ì  ë„êµ¬ ì‚¬ìš©ë²•
- **ROUGE** - í‰ê°€ ì§€í‘œ ìƒì„¸ ì„¤ëª…

### ğŸ“ í•™ìŠµ ìë£Œ
- **NLP ê¸°ì´ˆ** - ìì—°ì–´ ì²˜ë¦¬ ê¸°ë³¸ ê°œë…
- **Transformer ì•„í‚¤í…ì²˜** - íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ ì´í•´
- **ìš”ì•½ ê¸°ë²•** - í…ìŠ¤íŠ¸ ìš”ì•½ ë°©ë²•ë¡ 

### ğŸŒ ì»¤ë®¤ë‹ˆí‹°
- **GitHub ë¦¬í¬ì§€í† ë¦¬** - ê´€ë ¨ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸
- **ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼** - Stack Overflow, Reddit ë“±
- **ì»¨í¼ëŸ°ìŠ¤ ë° ì›Œí¬ìƒµ** - ê´€ë ¨ í•™íšŒ ë° í–‰ì‚¬ ì •ë³´

## ğŸ” í™œìš© ë°©ë²•

1. **í•™ìŠµ ì „** - ê¸°ë³¸ ê°œë… ë° ë°°ê²½ ì§€ì‹ ìŠµë“
2. **ê°œë°œ ì¤‘** - êµ¬ì²´ì ì¸ êµ¬í˜„ ë°©ë²• ì°¸ê³ 
3. **ë¬¸ì œ í•´ê²°** - ìœ ì‚¬í•œ ë¬¸ì œì˜ í•´ê²°ì±… ê²€ìƒ‰
4. **ì‹¬í™” í•™ìŠµ** - ê³ ê¸‰ ê¸°ë²• ë° ìµœì‹  ë™í–¥ íŒŒì•…

## ğŸ”— ê´€ë ¨ ë§í¬

- [ê¸°ìˆ  ë¬¸ì„œ](../03_technical_docs/README.md)
- [ê°œë°œì ê°€ì´ë“œ](../07_development/README.md)

---

# ğŸ”— ì£¼ìš” ì™¸ë¶€ ë§í¬ ë° ìë£Œ

## ğŸ“– ë…¼ë¬¸ ë° ì—°êµ¬ìë£Œ

### í•µì‹¬ ë…¼ë¬¸
- **[Attention Is All You Need](https://arxiv.org/abs/1706.03762)** - Transformer ì›ë…¼ë¬¸ (Vaswani et al., 2017)
  - *í™œìš©ëª©ì *: Transformer ì•„í‚¤í…ì²˜ì˜ ê¸°ë³¸ ì´í•´
  - *í•µì‹¬ë‚´ìš©*: Self-attention ë©”ì»¤ë‹ˆì¦˜ê³¼ Transformer êµ¬ì¡°

- **[BART: Denoising Sequence-to-Sequence Pre-training](https://arxiv.org/abs/1910.13461)** - BART ëª¨ë¸ ë…¼ë¬¸ (Lewis et al., 2019)
  - *í™œìš©ëª©ì *: KoBART ëª¨ë¸ì˜ ì´ë¡ ì  ë°°ê²½
  - *í•µì‹¬ë‚´ìš©*: Denoising autoencoder ë°©ì‹ì˜ ì‚¬ì „ í•™ìŠµ

- **[KoBART: Korean BART Pre-trained Model](https://github.com/SKT-AI/KoBART)** - SKT AI KoBART ëª¨ë¸
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ ìš”ì•½ ëª¨ë¸ì˜ ì§ì ‘ì  í™œìš©
  - *í•µì‹¬ë‚´ìš©*: í•œêµ­ì–´ íŠ¹í™” BART ëª¨ë¸ êµ¬í˜„

### ëŒ€í™” ìš”ì•½ íŠ¹í™” ë…¼ë¬¸
- **[DialogSum: A Real-Life Scenario Dialogue Summarization Dataset](https://arxiv.org/abs/2105.06762)** - DialogSum ë°ì´í„°ì…‹ (Chen et al., 2021)
  - *í™œìš©ëª©ì *: ëŒ€í™” ìš”ì•½ ë°ì´í„°ì…‹ ì„¤ê³„ ì°¸ê³ 
  - *í•µì‹¬ë‚´ìš©*: ì‹¤ì œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ìš”ì•½ ë°ì´í„°ì…‹

- **[Abstractive Dialogue Summarization with Sentence-Gated Modeling Optimized by Dialogue Acts](https://arxiv.org/abs/1809.05715)** - ëŒ€í™” ìš”ì•½ ìµœì í™” (Chen & Yang, 2020)
  - *í™œìš©ëª©ì *: ëŒ€í™” íŠ¹ì„±ì„ ë°˜ì˜í•œ ìš”ì•½ ë°©ë²•ë¡ 
  - *í•µì‹¬ë‚´ìš©*: Dialogue actsë¥¼ í™œìš©í•œ ìš”ì•½ ìµœì í™”

- **[PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://arxiv.org/abs/1912.08777)** - PEGASUS ëª¨ë¸ (Zhang et al., 2020)
  - *í™œìš©ëª©ì *: ìš”ì•½ íŠ¹í™” ì‚¬ì „ í•™ìŠµ ë°©ë²•ë¡ 
  - *í•µì‹¬ë‚´ìš©*: Gap-sentence generation ì‚¬ì „ í•™ìŠµ

### í•œêµ­ì–´ NLP ì—°êµ¬
- **[KoGPT: Korean Generative Pre-trained Transformer](https://github.com/kakaobrain/kogpt)** - ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ KoGPT
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ ìƒì„± ëª¨ë¸ ë¹„êµ ì—°êµ¬
  - *í•µì‹¬ë‚´ìš©*: í•œêµ­ì–´ ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸

- **[KcELECTRA: Korean comments ELECTRA](https://github.com/Beomi/KcELECTRA)** - í•œêµ­ì–´ ELECTRA ëª¨ë¸
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ ì¸ì½”ë” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
  - *í•µì‹¬ë‚´ìš©*: í•œêµ­ì–´ ëŒ“ê¸€ ë°ì´í„° ê¸°ë°˜ ELECTRA

## ğŸ› ï¸ ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ

### Hugging Face Ecosystem
- **[Transformers ê³µì‹ ë¬¸ì„œ](https://huggingface.co/docs/transformers/)**
  - *í™œìš©ëª©ì *: ëª¨ë¸ ë¡œë”©, í† í¬ë‚˜ì´ì €, í•™ìŠµ íŒŒì´í”„ë¼ì¸
  - *í•µì‹¬ì„¹ì…˜*: Model Hub, Training, Generation

- **[Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬](https://huggingface.co/docs/datasets/)**
  - *í™œìš©ëª©ì *: íš¨ìœ¨ì ì¸ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
  - *í•µì‹¬ì„¹ì…˜*: Loading datasets, Processing, Caching

- **[Tokenizers ê°€ì´ë“œ](https://huggingface.co/docs/tokenizers/)**
  - *í™œìš©ëª©ì *: ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì € êµ¬í˜„
  - *í•µì‹¬ì„¹ì…˜*: Encoding, Decoding, Special tokens

- **[Hugging Face Model Hub](https://huggingface.co/models)**
  - *í™œìš©ëª©ì *: ì‚¬ì „ í•™ìŠµëœ í•œêµ­ì–´ ëª¨ë¸ íƒìƒ‰
  - *ì¶”ì²œëª¨ë¸*: gogamza/kobart-base-v2, KETI-AIR/ke-t5-base

### PyTorch ê´€ë ¨
- **[PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/index.html)**
  - *í™œìš©ëª©ì *: ëª¨ë¸ êµ¬í˜„, ìµœì í™”, ë””ë°”ì´ìŠ¤ ê´€ë¦¬
  - *í•µì‹¬ì„¹ì…˜*: torch.nn, torch.optim, torch.cuda

- **[PyTorch Lightning](https://pytorch-lightning.readthedocs.io/)**
  - *í™œìš©ëª©ì *: êµ¬ì¡°í™”ëœ í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
  - *í•µì‹¬ì„¹ì…˜*: LightningModule, Trainer, Callbacks

- **[TorchMetrics](https://torchmetrics.readthedocs.io/)**
  - *í™œìš©ëª©ì *: í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„
  - *í•µì‹¬ì„¹ì…˜*: Text metrics, ROUGE, Custom metrics

### ì‹¤í—˜ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§
- **[Weights & Biases ê°€ì´ë“œ](https://docs.wandb.ai/)**
  - *í™œìš©ëª©ì *: ì‹¤í—˜ ì¶”ì , í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
  - *í•µì‹¬ì„¹ì…˜*: Experiment tracking, Sweeps, Reports

- **[MLflow ë¬¸ì„œ](https://mlflow.org/docs/latest/index.html)**
  - *í™œìš©ëª©ì *: ëª¨ë¸ ë²„ì „ ê´€ë¦¬, ë°°í¬
  - *í•µì‹¬ì„¹ì…˜*: Tracking, Model registry, Deployment

- **[TensorBoard ê°€ì´ë“œ](https://www.tensorflow.org/tensorboard)**
  - *í™œìš©ëª©ì *: í•™ìŠµ ê³¼ì • ì‹œê°í™”
  - *í•µì‹¬ì„¹ì…˜*: Scalars, Distributions, Histograms

### í‰ê°€ ë©”íŠ¸ë¦­
- **[ROUGE í‰ê°€ ì§€í‘œ ìƒì„¸ ì„¤ëª…](https://en.wikipedia.org/wiki/ROUGE_(metric))**
  - *í™œìš©ëª©ì *: ROUGE ë©”íŠ¸ë¦­ì˜ ì •í™•í•œ ì´í•´
  - *í•µì‹¬ë‚´ìš©*: ROUGE-1, ROUGE-2, ROUGE-L ì°¨ì´ì 

- **[rouge-score ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/google-research/google-research/tree/master/rouge)**
  - *í™œìš©ëª©ì *: ì •í™•í•œ ROUGE ì ìˆ˜ ê³„ì‚°
  - *í•µì‹¬ê¸°ëŠ¥*: Multi-reference evaluation

- **[BERTScore ë…¼ë¬¸ ë° êµ¬í˜„](https://github.com/Tiiiger/bert_score)**
  - *í™œìš©ëª©ì *: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ í‰ê°€
  - *í•µì‹¬ë‚´ìš©*: BERT embedding ê¸°ë°˜ í‰ê°€ ë©”íŠ¸ë¦­

## ğŸ“ í•™ìŠµ ë¦¬ì†ŒìŠ¤

### ê¸°ë³¸ ê°œë… í•™ìŠµ
- **[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)**
  - *í™œìš©ëª©ì *: Transformer êµ¬ì¡°ì˜ ì§ê´€ì  ì´í•´
  - *íŠ¹ì§•*: ì‹œê°ì  ì„¤ëª…ìœ¼ë¡œ ì‰¬ìš´ ì´í•´

- **[The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)**
  - *í™œìš©ëª©ì *: Transformer êµ¬í˜„ì˜ ìƒì„¸í•œ ì´í•´
  - *íŠ¹ì§•*: ì½”ë“œì™€ í•¨ê»˜ ì„¤ëª…

- **[Attention? Attention!](https://lilianweng.github.io/posts/2018-06-24-attention/)**
  - *í™œìš©ëª©ì *: Attention ë©”ì»¤ë‹ˆì¦˜ì˜ ë°œì „ ê³¼ì •
  - *íŠ¹ì§•*: ë‹¤ì–‘í•œ attention ë°©ë²• ë¹„êµ

### ì‹¤ë¬´ íŠœí† ë¦¬ì–¼
- **[Hugging Face Course - Summarization](https://huggingface.co/course/chapter7/5)**
  - *í™œìš©ëª©ì *: í…ìŠ¤íŠ¸ ìš”ì•½ ì‹¤ìŠµ
  - *íŠ¹ì§•*: ë‹¨ê³„ë³„ ì½”ë“œ ì˜ˆì œ

- **[Fine-tuning BART for Summarization](https://towardsdatascience.com/fine-tuning-bart-for-abstractive-text-summarization-d1c4b8de3938)**
  - *í™œìš©ëª©ì *: BART ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹¤ìŠµ
  - *íŠ¹ì§•*: ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì˜ˆì œ

- **[Korean NLP Tutorial](https://github.com/haven-jeon/KoNLTK)**
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ NLP ì „ì²˜ë¦¬ ë°©ë²•
  - *íŠ¹ì§•*: í•œêµ­ì–´ íŠ¹ì„± ê³ ë ¤í•œ ì „ì²˜ë¦¬

### ê³ ê¸‰ ê¸°ë²•
- **[Controllable Text Summarization](https://arxiv.org/abs/2005.07213)**
  - *í™œìš©ëª©ì *: ì œì–´ ê°€ëŠ¥í•œ ìš”ì•½ ìƒì„±
  - *í•µì‹¬ë‚´ìš©*: ê¸¸ì´, ìŠ¤íƒ€ì¼ ì œì–´ ë°©ë²•

- **[Few-Shot Learning for Text Summarization](https://arxiv.org/abs/2109.04309)**
  - *í™œìš©ëª©ì *: ì ì€ ë°ì´í„°ë¡œ ìš”ì•½ ëª¨ë¸ í•™ìŠµ
  - *í•µì‹¬ë‚´ìš©*: In-context learning, Meta-learning

## ğŸŒ ì»¤ë®¤ë‹ˆí‹° ë° ë¦¬ì†ŒìŠ¤

### GitHub ë¦¬í¬ì§€í† ë¦¬
- **[KoBART ê³µì‹ ì €ì¥ì†Œ](https://github.com/SKT-AI/KoBART)**
  - *í™œìš©ëª©ì *: KoBART ëª¨ë¸ ì‚¬ìš©ë²• ë° ì˜ˆì œ
  - *ì°¸ê³ ì½”ë“œ*: ìš”ì•½ íŒŒì¸íŠœë‹, ì¶”ë¡  ì˜ˆì œ

- **[Awesome Text Summarization](https://github.com/mathsyouth/awesome-text-summarization)**
  - *í™œìš©ëª©ì *: í…ìŠ¤íŠ¸ ìš”ì•½ ê´€ë ¨ ìë£Œ ì´ì§‘í•©
  - *í¬í•¨ë‚´ìš©*: ë…¼ë¬¸, ë°ì´í„°ì…‹, ë„êµ¬ ë§í¬

- **[Korean NLP Guide](https://github.com/songys/awesome-korean-nlp)**
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ NLP ë¦¬ì†ŒìŠ¤ ëª¨ìŒ
  - *í¬í•¨ë‚´ìš©*: ë°ì´í„°ì…‹, ëª¨ë¸, ë„êµ¬

- **[Transformers Examples](https://github.com/huggingface/transformers/tree/main/examples)**
  - *í™œìš©ëª©ì *: Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© ì˜ˆì œ
  - *ì°¸ê³ ë¶„ì•¼*: Summarization, Language modeling

### ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°
- **[Hugging Face Community](https://huggingface.co/discussions)**
  - *í™œìš©ëª©ì *: ëª¨ë¸ ê´€ë ¨ ì§ˆë¬¸ ë° í† ë¡ 
  - *ì£¼ìš”í† í”½*: Model usage, Training tips

- **[r/MachineLearning](https://www.reddit.com/r/MachineLearning/)**
  - *í™œìš©ëª©ì *: ìµœì‹  ML ì—°êµ¬ ë™í–¥ íŒŒì•…
  - *ì£¼ìš”í† í”½*: Paper discussions, Industry trends

- **[Stack Overflow - NLP](https://stackoverflow.com/questions/tagged/nlp)**
  - *í™œìš©ëª©ì *: êµ¬ì²´ì ì¸ êµ¬í˜„ ë¬¸ì œ í•´ê²°
  - *ì£¼ìš”í† í”½*: Code debugging, Implementation help

- **[Papers with Code - Text Summarization](https://paperswithcode.com/task/text-summarization)**
  - *í™œìš©ëª©ì *: ìµœì‹  ì—°êµ¬ ë° ë²¤ì¹˜ë§ˆí¬ í™•ì¸
  - *íŠ¹ì§•*: ë…¼ë¬¸ê³¼ êµ¬í˜„ ì½”ë“œ ì—°ê²°

### ì»¨í¼ëŸ°ìŠ¤ ë° ì›Œí¬ìƒµ
- **[ACL (Association for Computational Linguistics)](https://www.aclweb.org/)**
  - *í™œìš©ëª©ì *: NLP ìµœì‹  ì—°êµ¬ ë™í–¥
  - *ì£¼ìš”ì„¸ì…˜*: Summarization, Dialogue systems

- **[EMNLP (Empirical Methods in NLP)](https://2024.emnlp.org/)**
  - *í™œìš©ëª©ì *: ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ NLP ì—°êµ¬
  - *ì£¼ìš”ì„¸ì…˜*: Applications, Evaluation

- **[NeurIPS](https://neurips.cc/)**
  - *í™œìš©ëª©ì *: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ ì´ë¡  ë° ì•Œê³ ë¦¬ì¦˜
  - *ê´€ë ¨ë¶„ì•¼*: Deep learning, Optimization

- **[ICLR (International Conference on Learning Representations)](https://iclr.cc/)**
  - *í™œìš©ëª©ì *: ë”¥ëŸ¬ë‹ í‘œí˜„ í•™ìŠµ ì—°êµ¬
  - *ê´€ë ¨ë¶„ì•¼*: Transformer models, Pre-training

### ë°ì´í„°ì…‹ ë° ë²¤ì¹˜ë§ˆí¬
- **[DialogSum Dataset](https://huggingface.co/datasets/knkarthick/dialogsum)**
  - *í™œìš©ëª©ì *: ëŒ€í™” ìš”ì•½ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°
  - *íŠ¹ì§•*: ì‹¤ì œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜

- **[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)**
  - *í™œìš©ëª©ì *: ë‰´ìŠ¤ ìš”ì•½ ë²¤ì¹˜ë§ˆí¬
  - *íŠ¹ì§•*: ì¶”ìƒì  ìš”ì•½ í‰ê°€

- **[XSum](https://huggingface.co/datasets/xsum)**
  - *í™œìš©ëª©ì *: ê·¹ë„ë¡œ ì••ì¶•ëœ ìš”ì•½ í‰ê°€
  - *íŠ¹ì§•*: í•œ ë¬¸ì¥ ìš”ì•½ ìƒì„±

- **[Korean Multi-Reference Summarization](https://aihub.or.kr/)**
  - *í™œìš©ëª©ì *: í•œêµ­ì–´ ìš”ì•½ ë°ì´í„°
  - *ì¶œì²˜*: AI Hub í•œêµ­ì–´ ìš”ì•½ ë°ì´í„°ì…‹

## ğŸ”§ ê°œë°œ ë„êµ¬ ê°€ì´ë“œ

### IDE ë° ê°œë°œ í™˜ê²½
- **[VS Code Python Extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)**
  - *í™œìš©ëª©ì *: Python ê°œë°œ í™˜ê²½ ìµœì í™”
  - *ì£¼ìš”ê¸°ëŠ¥*: IntelliSense, Debugging, Linting

- **[Jupyter Lab](https://jupyterlab.readthedocs.io/)**
  - *í™œìš©ëª©ì *: ì‹¤í—˜ì  ì½”ë“œ ê°œë°œ ë° í”„ë¡œí† íƒ€ì´í•‘
  - *ì£¼ìš”ê¸°ëŠ¥*: Interactive computing, Visualization

- **[Google Colab Pro](https://colab.research.google.com/)**
  - *í™œìš©ëª©ì *: GPU ë¦¬ì†ŒìŠ¤ í™œìš©í•œ ëª¨ë¸ í•™ìŠµ
  - *ì£¼ìš”ê¸°ëŠ¥*: Free GPU/TPU, Easy sharing

### ë²„ì „ ê´€ë¦¬ ë° í˜‘ì—…
- **[DVC (Data Version Control)](https://dvc.org/)**
  - *í™œìš©ëª©ì *: ë°ì´í„° ë° ëª¨ë¸ ë²„ì „ ê´€ë¦¬
  - *ì£¼ìš”ê¸°ëŠ¥*: Data tracking, Pipeline management

- **[Git LFS](https://git-lfs.github.io/)**
  - *í™œìš©ëª©ì *: ëŒ€ìš©ëŸ‰ íŒŒì¼ ë²„ì „ ê´€ë¦¬
  - *ì‚¬ìš©ëŒ€ìƒ*: ëª¨ë¸ íŒŒì¼, ë°ì´í„°ì…‹

- **[pre-commit](https://pre-commit.com/)**
  - *í™œìš©ëª©ì *: ì½”ë“œ í’ˆì§ˆ ìë™ ê²€ì‚¬
  - *ì£¼ìš”ê¸°ëŠ¥*: Code formatting, Linting

### ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
- **[PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)**
  - *í™œìš©ëª©ì *: ëª¨ë¸ ì„±ëŠ¥ ë³‘ëª© ì§€ì  ë¶„ì„
  - *ì£¼ìš”ê¸°ëŠ¥*: GPU utilization, Memory usage

- **[memory_profiler](https://pypi.org/project/memory-profiler/)**
  - *í™œìš©ëª©ì *: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
  - *ì£¼ìš”ê¸°ëŠ¥*: Line-by-line memory usage

- **[cProfile](https://docs.python.org/3/library/profile.html)**
  - *í™œìš©ëª©ì *: CPU ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
  - *ì£¼ìš”ê¸°ëŠ¥*: Function call analysis

## ğŸ“Š í‰ê°€ ë° ë²¤ì¹˜ë§ˆí‚¹

### ìë™ í‰ê°€ ë„êµ¬
- **[NLTK BLEU](https://www.nltk.org/api/nltk.translate.html)**
  - *í™œìš©ëª©ì *: BLEU ì ìˆ˜ ê³„ì‚°
  - *íŠ¹ì§•*: ë‹¤ì–‘í•œ n-gram ì„¤ì •

- **[sacrebleu](https://github.com/mjpost/sacrebleu)**
  - *í™œìš©ëª©ì *: í‘œì¤€í™”ëœ BLEU ê³„ì‚°
  - *íŠ¹ì§•*: ì¬í˜„ ê°€ëŠ¥í•œ í‰ê°€

- **[METEOR](https://www.nltk.org/api/nltk.translate.html)**
  - *í™œìš©ëª©ì *: METEOR ì ìˆ˜ ê³„ì‚°
  - *íŠ¹ì§•*: ì–´ê°„ ë³€í™” ê³ ë ¤

### ì¸ê°„ í‰ê°€ ê°€ì´ë“œ
- **[Human Evaluation Guidelines for Text Summarization](https://arxiv.org/abs/2010.12233)**
  - *í™œìš©ëª©ì *: ì¸ê°„ í‰ê°€ ì„¤ê³„ ì°¸ê³ 
  - *í‰ê°€ìš”ì†Œ*: Fluency, Coherence, Relevance

- **[Crowdsourcing Evaluation](https://www.mturk.com/)**
  - *í™œìš©ëª©ì *: ëŒ€ê·œëª¨ ì¸ê°„ í‰ê°€ ìˆ˜í–‰
  - *í”Œë«í¼*: Amazon Mechanical Turk

## ğŸš€ ë°°í¬ ë° ìš´ì˜

### ëª¨ë¸ ì„œë¹™
- **[FastAPI](https://fastapi.tiangolo.com/)**
  - *í™œìš©ëª©ì *: REST API ì„œë²„ êµ¬ì¶•
  - *íŠ¹ì§•*: ìë™ ë¬¸ì„œ ìƒì„±, Type hints

- **[Gradio](https://gradio.app/)**
  - *í™œìš©ëª©ì *: ë¹ ë¥¸ ë°ëª¨ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•
  - *íŠ¹ì§•*: ì›¹ UI ìë™ ìƒì„±

- **[Streamlit](https://streamlit.io/)**
  - *í™œìš©ëª©ì *: ì¸í„°ë™í‹°ë¸Œ ì›¹ ì•± êµ¬ì¶•
  - *íŠ¹ì§•*: Python ê¸°ë°˜ ê°„í¸ ê°œë°œ

### í´ë¼ìš°ë“œ ë°°í¬
- **[Hugging Face Spaces](https://huggingface.co/spaces)**
  - *í™œìš©ëª©ì *: ë¬´ë£Œ ëª¨ë¸ ë°ëª¨ í˜¸ìŠ¤íŒ…
  - *íŠ¹ì§•*: Gradio/Streamlit ì§€ì›

- **[Google Cloud AI Platform](https://cloud.google.com/ai-platform)**
  - *í™œìš©ëª©ì *: ëŒ€ê·œëª¨ ëª¨ë¸ ì„œë¹™
  - *íŠ¹ì§•*: Auto-scaling, Load balancing

- **[AWS SageMaker](https://aws.amazon.com/sagemaker/)**
  - *í™œìš©ëª©ì *: ì—”í„°í”„ë¼ì´ì¦ˆ ML íŒŒì´í”„ë¼ì¸
  - *íŠ¹ì§•*: End-to-end ML workflow

## ğŸ“ˆ ìµœì‹  ë™í–¥ ë° ì—°êµ¬

### 2024ë…„ ì£¼ìš” ë°œì „ì‚¬í•­
- **[Large Language Models for Summarization](https://arxiv.org/abs/2401.00000)**
  - *íŠ¸ë Œë“œ*: LLMì„ í™œìš©í•œ ìš”ì•½ ìƒì„±
  - *ì£¼ìš”ëª¨ë¸*: GPT-4, Claude, LLaMA

- **[Retrieval-Augmented Summarization](https://arxiv.org/abs/2401.00001)**
  - *íŠ¸ë Œë“œ*: ì™¸ë¶€ ì§€ì‹ í™œìš© ìš”ì•½
  - *í•µì‹¬ê¸°ìˆ *: RAG, Knowledge graphs

- **[Multi-modal Dialogue Summarization](https://arxiv.org/abs/2401.00002)**
  - *íŠ¸ë Œë“œ*: í…ìŠ¤íŠ¸ ì™¸ ì •ë³´ í™œìš©
  - *í™•ì¥ì˜ì—­*: Audio, Video, Emotion

### í–¥í›„ ì—°êµ¬ ë°©í–¥
- **Controllable Generation** - ì‚¬ìš©ì ìš”êµ¬ì— ë§ëŠ” ë§ì¶¤í˜• ìš”ì•½
- **Cross-lingual Summarization** - ë‹¤êµ­ì–´ ê°„ ìš”ì•½ ìƒì„±
- **Real-time Summarization** - ì‹¤ì‹œê°„ ëŒ€í™” ìš”ì•½
- **Personalized Summarization** - ê°œì¸í™”ëœ ìš”ì•½ ìŠ¤íƒ€ì¼

---

## ğŸ’¡ í™œìš© íŒ

### íš¨ìœ¨ì ì¸ í•™ìŠµ ìˆœì„œ
1. **ê¸°ì´ˆ ì´ë¡ ** â†’ Transformer, BART ë…¼ë¬¸ ì½ê¸°
2. **ì‹¤ìŠµ ê²½í—˜** â†’ Hugging Face Course ì™„ì£¼
3. **í•œêµ­ì–´ íŠ¹í™”** â†’ KoBART, í•œêµ­ì–´ NLP ìë£Œ í•™ìŠµ
4. **ì‹¬í™” ì—°êµ¬** â†’ ìµœì‹  ë…¼ë¬¸ ë° ê³ ê¸‰ ê¸°ë²• íƒêµ¬

### ë¬¸ì œ í•´ê²° ì „ëµ
1. **ê³µì‹ ë¬¸ì„œ ìš°ì„ ** â†’ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê³µì‹ ê°€ì´ë“œ í™•ì¸
2. **ì»¤ë®¤ë‹ˆí‹° í™œìš©** â†’ Stack Overflow, GitHub Issues ê²€ìƒ‰
3. **ì‹¤í—˜ì  ì ‘ê·¼** â†’ ì‘ì€ ê·œëª¨ë¡œ í…ŒìŠ¤íŠ¸ í›„ í™•ì¥
4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§** â†’ ì§€ì†ì ì¸ í‰ê°€ ë° ê°œì„ 

### í”„ë¡œì íŠ¸ ì§„í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ê¸°ë³¸ ë…¼ë¬¸ 3í¸ ì´ìƒ ì½ê¸°
- [ ] Hugging Face Transformers ì‹¤ìŠµ ì™„ë£Œ
- [ ] í•œêµ­ì–´ ë°ì´í„° ì „ì²˜ë¦¬ ë°©ë²• ìˆ™ì§€
- [ ] ROUGE í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ì‹¤í—˜ ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ëª¨ë¸ ë°°í¬ íŒŒì´í”„ë¼ì¸ ì„¤ê³„

ì´ ì°¸ê³  ìë£Œë“¤ì„ í†µí•´ NLP ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸ì˜ ì´ë¡ ì  ë°°ê²½ë¶€í„° ì‹¤ë¬´ ì ìš©ê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
