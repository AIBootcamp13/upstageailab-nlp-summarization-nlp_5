#!/bin/bash

echo "=== MKL í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° (uv + conda ë³‘í–‰) ==="

# 1. í™˜ê²½ í™œì„±í™”
eval "$(/opt/conda/bin/conda shell.bash hook)"
conda activate venv

# 2. í˜„ì¬ MKL ë²„ì „ í™•ì¸
echo "2. í˜„ì¬ MKL ë²„ì „ í™•ì¸..."
conda list | grep mkl

# 3. MKL ë‹¤ìš´ê·¸ë ˆì´ë“œ (condaë¡œ)
echo "3. MKLì„ 2024.0.0ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ..."
conda install mkl=2024.0 -y

# 4. uvë¡œ ëª¨ë“  PyTorch ê´€ë ¨ íŒ¨í‚¤ì§€ ì œê±°
echo "4. uvë¡œ ê¸°ì¡´ íŒ¨í‚¤ì§€ ì œê±°..."
uv pip uninstall torch torchvision torchaudio bitsandbytes unsloth transformers datasets accelerate gradio wandb -q || true

# 5. uvë¡œ PyTorch ì„¤ì¹˜ (MKL í˜¸í™˜ í›„)
echo "5. uvë¡œ PyTorch CUDA 12.1 ì„¤ì¹˜..."
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 6. ì„¤ì¹˜ í™•ì¸
echo "6. PyTorch ì„¤ì¹˜ í™•ì¸..."
python -c "
import torch
print(f'âœ… PyTorch: {torch.__version__}')
print(f'   CUDA: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'   GPU: {torch.cuda.get_device_name(0)}')
    print(f'   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory // (1024**3)}GB')
    # ê°„ë‹¨í•œ GPU ì—°ì‚° í…ŒìŠ¤íŠ¸
    x = torch.randn(100, 100).cuda()
    y = x @ x.T
    print('   âœ… GPU ì—°ì‚° ì„±ê³µ')
else:
    print('   âš ï¸ CPU ëª¨ë“œ')
"

# 7. uvë¡œ ë‹¤ë¥¸ íŒ¨í‚¤ì§€ë“¤ ì„¤ì¹˜
echo "7. uvë¡œ ë‹¤ë¥¸ íŒ¨í‚¤ì§€ë“¤ ì„¤ì¹˜..."
uv pip install transformers datasets accelerate gradio wandb

# 8. uvë¡œ bitsandbytes ì„¤ì¹˜ (MKL ìˆ˜ì • í›„)
echo "8. uvë¡œ bitsandbytes ì„¤ì¹˜..."
uv pip install bitsandbytes --no-cache-dir

# 9. uvë¡œ unsloth ì„¤ì¹˜
echo "9. uvë¡œ unsloth ì„¤ì¹˜..."
uv pip install unsloth --no-cache-dir

# 10. ìµœì¢… ì¢…í•© í…ŒìŠ¤íŠ¸
echo "10. ìµœì¢… ì¢…í•© í…ŒìŠ¤íŠ¸..."
python -c "
print('=== ìµœì¢… ê²€ì¦ ===')

# PyTorch í…ŒìŠ¤íŠ¸
try:
    import torch
    print(f'âœ… PyTorch: {torch.__version__}')
    print(f'   CUDA: {torch.cuda.is_available()}')
    if torch.cuda.is_available():
        print(f'   GPU: {torch.cuda.get_device_name(0)}')
except Exception as e:
    print(f'âŒ PyTorch ì˜¤ë¥˜: {e}')
    exit(1)

# transformers í…ŒìŠ¤íŠ¸
try:
    import transformers
    print(f'âœ… Transformers: {transformers.__version__}')
except Exception as e:
    print(f'âŒ Transformers ì˜¤ë¥˜: {e}')

# bitsandbytes í…ŒìŠ¤íŠ¸
try:
    import bitsandbytes as bnb
    print('âœ… bitsandbytes: ì„í¬íŠ¸ ì„±ê³µ')
    if torch.cuda.is_available():
        # ê°„ë‹¨í•œ ì–‘ìí™” í…ŒìŠ¤íŠ¸
        linear = bnb.nn.Linear8bitLt(10, 10).cuda()
        x = torch.randn(5, 10).cuda()
        out = linear(x)
        print('âœ… bitsandbytes: GPU ì–‘ìí™” ì„±ê³µ')
except Exception as e:
    print(f'âŒ bitsandbytes ì˜¤ë¥˜: {e}')

# unsloth ìµœì¢… í…ŒìŠ¤íŠ¸
try:
    from unsloth import FastLanguageModel
    print('âœ… unsloth: FastLanguageModel ì„í¬íŠ¸ ì„±ê³µ')
    print('\\nğŸ‰ ëª¨ë“  íŒ¨í‚¤ì§€ê°€ ì™„ë²½í•˜ê²Œ ì‘ë™í•©ë‹ˆë‹¤!')
except Exception as e:
    print(f'âŒ unsloth ì˜¤ë¥˜: {e}')
    print('í•˜ì§€ë§Œ ê¸°ë³¸ íŒ¨í‚¤ì§€ë“¤ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.')
"

# 11. MKL ë²„ì „ ê³ ì • (í–¥í›„ ì—…ë°ì´íŠ¸ ë°©ì§€)
echo "11. MKL ë²„ì „ ê³ ì •..."
conda pin add mkl=2024.0

# 12. ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ í™•ì¸
echo "12. ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ í™•ì¸..."
echo "=== conda íŒ¨í‚¤ì§€ (MKL ê´€ë ¨) ==="
conda list | grep mkl
echo ""
echo "=== uv íŒ¨í‚¤ì§€ (PyTorch ê´€ë ¨) ==="
uv pip list | grep -E "(torch|bitsandbytes|unsloth|transformers)"

echo ""
echo "=== MKL í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° ì™„ë£Œ ==="
echo ""
echo "- MKL: condaë¡œ 2024.0.0 ì„¤ì¹˜ ë° ê³ ì •"
echo "- PyTorch ê´€ë ¨: uvë¡œ ì„¤ì¹˜"
echo "- ì´ì œ unslothê°€ ì •ìƒ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤."
echo ""
echo "ìµœì¢… í™•ì¸:"
echo "python -c \"from unsloth import FastLanguageModel; print('âœ… ì™„ë£Œ')\""
