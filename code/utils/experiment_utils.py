"""
ì‹¤í—˜ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°

NLP ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë“±ë¡, ê²°ê³¼ ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
WandBì™€ ì—°ë™í•˜ì—¬ ì²´ê³„ì ì¸ ì‹¤í—˜ ê´€ë¦¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
"""

import os
import json
import pickle
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
import logging
import pandas as pd
import numpy as np
from collections import defaultdict


@dataclass
class ExperimentInfo:
    """ì‹¤í—˜ ì •ë³´ í´ë˜ìŠ¤"""
    experiment_id: str
    name: str
    description: str
    config: Dict[str, Any]
    model_type: str
    dataset_info: Dict[str, Any]
    start_time: str
    end_time: Optional[str] = None
    status: str = "ì‹¤í–‰ì¤‘"  # ì‹¤í–‰ì¤‘, ì™„ë£Œ, ì‹¤íŒ¨
    best_metrics: Optional[Dict[str, float]] = None
    final_metrics: Optional[Dict[str, float]] = None
    model_path: Optional[str] = None
    wandb_run_id: Optional[str] = None
    notes: Optional[str] = None


@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´ í´ë˜ìŠ¤"""
    model_id: str
    name: str
    architecture: str
    checkpoint: str
    config: Dict[str, Any]
    performance: Dict[str, float]
    training_info: Dict[str, Any]
    file_path: str
    created_at: str
    experiment_id: Optional[str] = None
    tags: Optional[List[str]] = None


class ExperimentTracker:
    """
    ì‹¤í—˜ ì¶”ì ê¸°
    
    ì‹¤í—˜ ì •ë³´ ì €ì¥, ë¡œë”©, ë¹„êµ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, experiments_dir: Union[str, Path] = "./experiments"):
        """
        ExperimentTracker ì´ˆê¸°í™”
        
        Args:
            experiments_dir: ì‹¤í—˜ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.experiments_dir = Path(experiments_dir)
        self.experiments_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger = logging.getLogger(__name__)
        self.current_experiment = None
        
        # ì‹¤í—˜ ë°ì´í„°ë² ì´ìŠ¤ (JSON íŒŒì¼)
        self.db_path = self.experiments_dir / "experiments.json"
        self.experiments_db = self._load_experiments_db()
    
    def start_experiment(self, name: str, description: str, 
                        config: Dict[str, Any], model_type: str,
                        dataset_info: Optional[Dict[str, Any]] = None,
                        wandb_run_id: Optional[str] = None) -> str:
        """
        ìƒˆë¡œìš´ ì‹¤í—˜ ì‹œì‘
        
        Args:
            name: ì‹¤í—˜ëª…
            description: ì‹¤í—˜ ì„¤ëª…
            config: ì‹¤í—˜ ì„¤ì •
            model_type: ëª¨ë¸ íƒ€ì…
            dataset_info: ë°ì´í„°ì…‹ ì •ë³´
            wandb_run_id: WandB ì‹¤í–‰ ID
            
        Returns:
            ì‹¤í—˜ ID
        """
        # ì‹¤í—˜ ID ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ + ì„¤ì • í•´ì‹œ)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        config_hash = self._hash_config(config)
        experiment_id = f"{timestamp}_{config_hash[:8]}"
        
        # ì‹¤í—˜ ì •ë³´ ìƒì„±
        experiment_info = ExperimentInfo(
            experiment_id=experiment_id,
            name=name,
            description=description,
            config=config,
            model_type=model_type,
            dataset_info=dataset_info or {},
            start_time=datetime.now().isoformat(),
            wandb_run_id=wandb_run_id
        )
        
        # ì‹¤í—˜ ë””ë ‰í† ë¦¬ ìƒì„±
        exp_dir = self.experiments_dir / experiment_id
        exp_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤í—˜ ì •ë³´ ì €ì¥
        self._save_experiment_info(experiment_info)
        
        # í˜„ì¬ ì‹¤í—˜ìœ¼ë¡œ ì„¤ì •
        self.current_experiment = experiment_info
        
        self.logger.info(f"Started experiment: {experiment_id} - {name}")
        return experiment_id
    
    def complete_experiment(self, experiment_id: Optional[str] = None,
                          final_metrics: Optional[Dict[str, float]] = None,
                          model_path: Optional[str] = None,
                          notes: Optional[str] = None):
        """
        ì‹¤í—˜ ì™„ë£Œ ì²˜ë¦¬
        
        Args:
            experiment_id: ì‹¤í—˜ ID
            final_metrics: ìµœì¢… ë©”íŠ¸ë¦­
            model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            notes: ì¶”ê°€ ë…¸íŠ¸
        """
        self.update_experiment(
            experiment_id=experiment_id,
            status="completed",
            end_time=datetime.now().isoformat(),
            final_metrics=final_metrics,
            model_path=model_path,
            notes=notes
        )
        
        exp_id = experiment_id or self.current_experiment.experiment_id
        self.logger.info(f"Completed experiment: {exp_id}")
    
    def end_experiment(self, experiment_id: Optional[str] = None,
                      final_metrics: Optional[Dict[str, float]] = None,
                      model_path: Optional[str] = None,
                      status: str = "completed",
                      notes: Optional[str] = None):
        """
        ì‹¤í—˜ ì¢…ë£Œ (ì»´í”Œë¦¬íŠ¸ ì‹¤í—˜ì˜ ì—ì¼ë¦¬ì–´ìŠ¤)
        
        Args:
            experiment_id: ì‹¤í—˜ ID (ì—†ìœ¼ë©´ í˜„ì¬ ì‹¤í—˜ ì‚¬ìš©)
            final_metrics: ìµœì¢… ë©”íŠ¸ë¦­
            model_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            status: ì‹¤í—˜ ìƒíƒœ
            notes: ì¶”ê°€ ë…¸íŠ¸
        """
        # update_experimentë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ status ì²˜ë¦¬
        self.update_experiment(
            experiment_id=experiment_id,
            status=status,
            end_time=datetime.now().isoformat(),
            final_metrics=final_metrics,
            model_path=model_path,
            notes=notes
        )
        
        exp_id = experiment_id or self.current_experiment.experiment_id
        self.logger.info(f"Ended experiment: {exp_id}")
    def update_experiment(self, experiment_id: Optional[str] = None, **kwargs):
        """ì‹¤í—˜ ì •ë³´ ì—…ë°ì´íŠ¸"""
        if experiment_id is None:
            if self.current_experiment is None:
                raise ValueError("No current experiment and no experiment_id provided")
            experiment_info = self.current_experiment
        else:
            experiment_info = self._load_experiment_info(experiment_id)
        
        # í•„ë“œ ì—…ë°ì´íŠ¸
        for field, value in kwargs.items():
            if hasattr(experiment_info, field):
                setattr(experiment_info, field, value)
        
        # ì €ì¥
        self._save_experiment_info(experiment_info)
        
        if experiment_id is None or experiment_id == self.current_experiment.experiment_id:
            self.current_experiment = experiment_info
        
        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None):
        """
        ë©”íŠ¸ë¦­ ë¡œê¹…
        
        Args:
            metrics: ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            step: ë‹¨ê³„ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)
        """
        if not self.current_experiment:
            self.logger.warning("âš ï¸  í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë©”íŠ¸ë¦­ ë¡œê¹… (ê°„ë‹¨í•œ ì •ë³´ë§Œ)
        if step is not None:
            self.logger.info(f"ğŸ“Š Step {step} metrics logged")
        else:
            self.logger.info("ğŸ“Š Metrics logged")
        
        # best_metrics ì—…ë°ì´íŠ¸ (ì£¼ìš” ë©”íŠ¸ë¦­ë§Œ)
        rouge_combined = metrics.get('eval_rouge_combined_f1', 0) or metrics.get('rouge_combined_f1', 0)
        if rouge_combined > 0:
            current_best = self.current_experiment.best_metrics or {}
            if rouge_combined > current_best.get('rouge_combined_f1', 0):
                self.current_experiment.best_metrics = {
                    'rouge_combined_f1': rouge_combined,
                    'rouge1_f1': metrics.get('eval_rouge1_f1', 0) or metrics.get('rouge1_f1', 0),
                    'rouge2_f1': metrics.get('eval_rouge2_f1', 0) or metrics.get('rouge2_f1', 0),
                    'rougeL_f1': metrics.get('eval_rougeL_f1', 0) or metrics.get('rougeL_f1', 0)
                }
                self._save_experiment_info(self.current_experiment)
                self.logger.info(f"ğŸ† New best combined F1: {rouge_combined:.4f}")
                
                def get_experiment_list(self, status: Optional[str] = None) -> List[ExperimentInfo]:
                """ì‹¤í—˜ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ"""
                experiments = []
                exp_info = self._load_experiment_info(exp_id)
                if status is None or exp_info.status == status:
                experiments.append(exp_info)
        
        # ì‹œì‘ ì‹œê°„ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        experiments.sort(key=lambda x: x.start_time, reverse=True)
        return experiments
    
    def get_best_experiments(self, metric: str = "rouge_combined_f1", 
                           top_k: int = 5) -> List[ExperimentInfo]:
        """ìµœê³  ì„±ëŠ¥ ì‹¤í—˜ë“¤ ì¡°íšŒ"""
        experiments = self.get_experiment_list(status="completed")
        
        # ë©”íŠ¸ë¦­ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        experiments_with_metric = []
        for exp in experiments:
            if exp.best_metrics and metric in exp.best_metrics:
                experiments_with_metric.append((exp, exp.best_metrics[metric]))
        
        # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        experiments_with_metric.sort(key=lambda x: x[1], reverse=True)
        
        return [exp for exp, _ in experiments_with_metric[:top_k]]
    
    def _load_experiments_db(self) -> Dict[str, Any]:
        """ì‹¤í—˜ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”©"""
        if self.db_path.exists():
            with open(self.db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_experiments_db(self):
        """ì‹¤í—˜ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        with open(self.db_path, 'w', encoding='utf-8') as f:
            json.dump(self.experiments_db, f, ensure_ascii=False, indent=2)
    
    def _save_experiment_info(self, experiment_info: ExperimentInfo):
        """ì‹¤í—˜ ì •ë³´ ì €ì¥"""
        exp_dir = self.experiments_dir / experiment_info.experiment_id
        info_file = exp_dir / "experiment_info.json"
        
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(experiment_info), f, ensure_ascii=False, indent=2)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
        self.experiments_db[experiment_info.experiment_id] = {
            'name': experiment_info.name,
            'status': experiment_info.status,
            'start_time': experiment_info.start_time,
            'model_type': experiment_info.model_type
        }
        self._save_experiments_db()
    
    def _load_experiment_info(self, experiment_id: str) -> ExperimentInfo:
        """ì‹¤í—˜ ì •ë³´ ë¡œë”©"""
        info_file = self.experiments_dir / experiment_id / "experiment_info.json"
        
        if not info_file.exists():
            raise FileNotFoundError(f"Experiment not found: {experiment_id}")
        
        with open(info_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return ExperimentInfo(**data)
    
    def _hash_config(self, config: Dict[str, Any]) -> str:
        """ì„¤ì • í•´ì‹œ ìƒì„±"""
        config_str = json.dumps(config, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(config_str.encode()).hexdigest()
        
        def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None):
        """
        ë©”íŠ¸ë¦­ ë¡œê¹…
        
        Args:
            metrics: ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
            step: ë‹¨ê³„ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)
        """
        if not self.current_experiment:
            self.logger.warning("âš ï¸  í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë©”íŠ¸ë¦­ ë¡œê¹… (ê°„ë‹¨í•œ ì •ë³´ë§Œ)
        if step is not None:
            self.logger.info(f"ğŸ“Š Step {step} metrics logged")
        else:
            self.logger.info("ğŸ“Š Metrics logged")
        
        # best_metrics ì—…ë°ì´íŠ¸ (ì£¼ìš” ë©”íŠ¸ë¦­ë§Œ)
        rouge_combined = metrics.get('eval_rouge_combined_f1', 0) or metrics.get('rouge_combined_f1', 0)
        if rouge_combined > 0:
            current_best = self.current_experiment.best_metrics or {}
            if rouge_combined > current_best.get('rouge_combined_f1', 0):
                self.current_experiment.best_metrics = {
                    'rouge_combined_f1': rouge_combined,
                    'rouge1_f1': metrics.get('eval_rouge1_f1', 0) or metrics.get('rouge1_f1', 0),
                    'rouge2_f1': metrics.get('eval_rouge2_f1', 0) or metrics.get('rouge2_f1', 0),
                    'rougeL_f1': metrics.get('eval_rougeL_f1', 0) or metrics.get('rougeL_f1', 0)
                }
                self._save_experiment_info(self.current_experiment)
                self.logger.info(f"ğŸ† New best combined F1: {rouge_combined:.4f}")


class ModelRegistry:
    """ëª¨ë¸ ë“±ë¡ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, models_dir: Union[str, Path] = "./models"):
        """ModelRegistry ì´ˆê¸°í™”"""
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger = logging.getLogger(__name__)
        
        # ëª¨ë¸ ë°ì´í„°ë² ì´ìŠ¤
        self.db_path = self.models_dir / "models.json"
        self.models_db = self._load_models_db()
    
    def register_model(self, name: str, architecture: str, checkpoint: str,
                      config: Dict[str, Any], performance: Dict[str, float],
                      training_info: Dict[str, Any], file_path: str,
                      experiment_id: Optional[str] = None,
                      tags: Optional[List[str]] = None) -> str:
        """ëª¨ë¸ ë“±ë¡"""
        # ëª¨ë¸ ID ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        name_hash = hashlib.md5(name.encode()).hexdigest()[:8]
        model_id = f"{architecture}_{timestamp}_{name_hash}"
        
        # ëª¨ë¸ ì •ë³´ ìƒì„±
        model_info = ModelInfo(
            model_id=model_id,
            name=name,
            architecture=architecture,
            checkpoint=checkpoint,
            config=config,
            performance=performance,
            training_info=training_info,
            file_path=file_path,
            created_at=datetime.now().isoformat(),
            experiment_id=experiment_id,
            tags=tags or []
        )
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        self._save_model_info(model_info)
        
        self.logger.info(f"Registered model: {model_id} - {name}")
        return model_id
    
    def _load_models_db(self) -> Dict[str, Any]:
        """ëª¨ë¸ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”©"""
        if self.db_path.exists():
            with open(self.db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_models_db(self):
        """ëª¨ë¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        with open(self.db_path, 'w', encoding='utf-8') as f:
            json.dump(self.models_db, f, ensure_ascii=False, indent=2)
    
    def _save_model_info(self, model_info: ModelInfo):
        """ëª¨ë¸ ì •ë³´ ì €ì¥"""
        info_file = self.models_dir / f"{model_info.model_id}.json"
        
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(model_info), f, ensure_ascii=False, indent=2)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
        self.models_db[model_info.model_id] = {
            'name': model_info.name,
            'architecture': model_info.architecture,
            'created_at': model_info.created_at,
            'main_metric': model_info.performance.get('rouge_combined_f1', 0.0)
        }
        self._save_models_db()
    
    def _load_model_info(self, model_id: str) -> ModelInfo:
        """ëª¨ë¸ ì •ë³´ ë¡œë”©"""
        info_file = self.models_dir / f"{model_id}.json"
        
        if not info_file.exists():
            raise FileNotFoundError(f"Model not found: {model_id}")
        
        with open(info_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return ModelInfo(**data)
    
    def get_model_info(self, model_name: str) -> Optional[Dict[str, Any]]:
        """
        ëª¨ë¸ëª…ì— ë”°ë¥¸ ëª¨ë¸ ì •ë³´ ë°˜í™˜
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (e.g., 't5-base-korean-summarization')
            
        Returns:
            ëª¨ë¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        # ì•Œë ¤ì§„ ëª¨ë¸ë“¤ì— ëŒ€í•œ ì •ë³´ ë§¤í•‘
        model_name_lower = model_name.lower()
        
        # T5 ê¸°ë°˜ ëª¨ë¸ë“¤
        if any(keyword in model_name_lower for keyword in ['t5', 'flan-t5', 'mt5']):
            return {
                'architecture': 't5',
                'model_type': 'seq2seq',
                'recommended_params': {
                    'learning_rate': 3e-5,
                    'batch_size': 4,
                    'gradient_accumulation_steps': 2,
                    'num_epochs': 3
                },
                'memory_requirements': 'medium' if 'base' in model_name_lower else 'high'
            }
        
        # BART/KoBART ê¸°ë°˜ ëª¨ë¸ë“¤  
        elif any(keyword in model_name_lower for keyword in ['bart', 'kobart']):
            return {
                'architecture': 'bart',
                'model_type': 'seq2seq',
                'recommended_params': {
                    'learning_rate': 2e-5,
                    'batch_size': 8,
                    'gradient_accumulation_steps': 1,
                    'num_epochs': 5
                },
                'memory_requirements': 'low' if 'ko' in model_name_lower else 'medium'
            }
        
        # GPT ê¸°ë°˜ ëª¨ë¸ë“¤
        elif any(keyword in model_name_lower for keyword in ['gpt', 'kogpt']):
            return {
                'architecture': 'gpt',
                'model_type': 'causal_lm',
                'recommended_params': {
                    'learning_rate': 1e-5,
                    'batch_size': 2,
                    'gradient_accumulation_steps': 4,
                    'num_epochs': 3
                },
                'memory_requirements': 'very_high'
            }
        
        # Polyglot ê¸°ë°˜ ëª¨ë¸ë“¤
        elif 'polyglot' in model_name_lower:
            return {
                'architecture': 'gpt-neox',
                'model_type': 'causal_lm',
                'recommended_params': {
                    'learning_rate': 2e-5,
                    'batch_size': 4,
                    'gradient_accumulation_steps': 2,
                    'num_epochs': 3
                },
                'memory_requirements': 'high'
            }
        
        # eenzeenee ëª¨ë¸ ì§ì ‘ ì§€ì›
        elif 'eenzeenee' in model_name_lower:
            return {
                'architecture': 't5',
                'model_type': 'seq2seq',
                'recommended_params': {
                    'learning_rate': 3e-5,
                    'batch_size': 8,
                    'gradient_accumulation_steps': 1,
                    'num_epochs': 5
                },
                'memory_requirements': 'medium',
                'requires_prefix': True,
                'input_prefix': 'summarize: '
            }
        
        # ê¸°ë³¸ ì§€ì› ëª¨ë¸ë“¤ (KoBART ë“±)
        elif any(keyword in model_name_lower for keyword in ['kobart', 'digit82']):
            return {
                'architecture': 'bart',
                'model_type': 'seq2seq',
                'recommended_params': {
                    'learning_rate': 2e-5,
                    'batch_size': 8,
                    'gradient_accumulation_steps': 1,
                    'num_epochs': 5
                },
                'memory_requirements': 'low'
            }
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ì˜ ê²½ìš° None ë°˜í™˜
        self.logger.warning(f"Unknown model: {model_name}. Returning None.")
        return None


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_experiment_tracker(experiments_dir: str = "./experiments") -> ExperimentTracker:
    """ì‹¤í—˜ ì¶”ì ê¸° ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return ExperimentTracker(experiments_dir)


def create_model_registry(models_dir: str = "./models") -> ModelRegistry:
    """ëª¨ë¸ ë“±ë¡ê¸° ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return ModelRegistry(models_dir)
